{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f6b8904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-31T10:25:54.253440Z",
     "iopub.status.busy": "2023-12-31T10:25:54.253172Z",
     "iopub.status.idle": "2023-12-31T10:29:38.769907Z",
     "shell.execute_reply": "2023-12-31T10:29:38.768722Z"
    },
    "executionInfo": {
     "elapsed": 101002,
     "status": "ok",
     "timestamp": 1701611708946,
     "user": {
      "displayName": "Sugarbayar Enkhbayar",
      "userId": "11356332751747853171"
     },
     "user_tz": -60
    },
    "id": "DIGxZktU0iW_",
    "outputId": "3549d287-1c37-4fea-dde8-aaec56071f79",
    "papermill": {
     "duration": 224.527156,
     "end_time": "2023-12-31T10:29:38.772520",
     "exception": false,
     "start_time": "2023-12-31T10:25:54.245364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\sugar\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\sugar\\anaconda3\\lib\\site-packages (3.0.10)\n",
      "Requirement already satisfied: et_xmlfile in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\sugar\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from xgboost) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sugar\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: iteration_utilities in c:\\users\\sugar\\anaconda3\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: ta in c:\\users\\sugar\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from ta) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from ta) (2.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas->ta) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas->ta) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas->ta) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->ta) (1.16.0)\n",
      "Requirement already satisfied: MetaTrader5 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (5.0.4200)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from MetaTrader5) (1.26.4)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\sugar\\anaconda3\\lib\\site-packages (3.0.10)\n",
      "Requirement already satisfied: et_xmlfile in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\sugar\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\sugar\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from plotly) (8.2.2)\n",
      "Requirement already satisfied: ffn in c:\\users\\sugar\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: decorator>=5.0.7 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from ffn) (5.1.1)\n",
      "Requirement already satisfied: matplotlib>=1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from ffn) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.5 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from ffn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.19 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from ffn) (2.1.4)\n",
      "Requirement already satisfied: pandas-datareader>=0.2 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from ffn) (0.10.0)\n",
      "Requirement already satisfied: scikit-learn>=0.15 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from ffn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=0.15 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from ffn) (1.11.4)\n",
      "Requirement already satisfied: tabulate>=0.7.5 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from ffn) (0.9.0)\n",
      "Requirement already satisfied: yfinance>=0.2 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from ffn) (0.2.37)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=1->ffn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=1->ffn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=1->ffn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=1->ffn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=1->ffn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=1->ffn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=1->ffn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=1->ffn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas>=0.19->ffn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas>=0.19->ffn) (2023.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas-datareader>=0.2->ffn) (4.9.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas-datareader>=0.2->ffn) (2.31.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-learn>=0.15->ffn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-learn>=0.15->ffn) (2.2.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from yfinance>=0.2->ffn) (0.0.11)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from yfinance>=0.2->ffn) (1.4.4)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from yfinance>=0.2->ffn) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from yfinance>=0.2->ffn) (3.17.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from yfinance>=0.2->ffn) (4.12.2)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from yfinance>=0.2->ffn) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance>=0.2->ffn) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance>=0.2->ffn) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance>=0.2->ffn) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn) (2024.2.2)\n",
      "Requirement already satisfied: quantstats in c:\\users\\sugar\\anaconda3\\lib\\site-packages (0.0.62)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from quantstats) (2.1.4)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from quantstats) (1.26.4)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from quantstats) (0.12.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from quantstats) (3.8.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from quantstats) (1.11.4)\n",
      "Requirement already satisfied: tabulate>=0.8.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from quantstats) (0.9.0)\n",
      "Requirement already satisfied: yfinance>=0.1.70 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from quantstats) (0.2.37)\n",
      "Requirement already satisfied: python-dateutil>=2.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from quantstats) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->quantstats) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->quantstats) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->quantstats) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->quantstats) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->quantstats) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->quantstats) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->quantstats) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->quantstats) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->quantstats) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from python-dateutil>=2.0->quantstats) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from yfinance>=0.1.70->quantstats) (2.31.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from yfinance>=0.1.70->quantstats) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from yfinance>=0.1.70->quantstats) (4.9.3)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from yfinance>=0.1.70->quantstats) (1.4.4)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from yfinance>=0.1.70->quantstats) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from yfinance>=0.1.70->quantstats) (3.17.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from yfinance>=0.1.70->quantstats) (4.12.2)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from yfinance>=0.1.70->quantstats) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance>=0.1.70->quantstats) (2.5)\n",
      "Requirement already satisfied: webencodings in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance>=0.1.70->quantstats) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance>=0.1.70->quantstats) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance>=0.1.70->quantstats) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance>=0.1.70->quantstats) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance>=0.1.70->quantstats) (2024.2.2)\n",
      "Requirement already satisfied: scikit-optimize in c:\\users\\sugar\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.2.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-optimize) (23.12.0)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.4.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-optimize) (23.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikit-optimize) (2.2.0)\n",
      "Requirement already satisfied: keras in c:\\users\\sugar\\anaconda3\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: pandas_ta in c:\\users\\sugar\\anaconda3\\lib\\site-packages (0.3.14b0)\n",
      "Requirement already satisfied: pandas in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas_ta) (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.16.0)\n",
      "Requirement already satisfied: scikeras in c:\\users\\sugar\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikeras) (3.2.1)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikeras) (1.4.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.3.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sugar\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------- Install packages\n",
    "# !{sys.executable} -m pip install ta --user\n",
    "# !{sys.executable} -m pip install datetime --user\n",
    "# !{sys.executable} -m pip install MetaTrader5 --user\n",
    "# ! pip install mpl_finance\n",
    "# ! pip install mplfinance\n",
    "# ! conda install -c anaconda numpy\n",
    "! pip install pandas\n",
    "! pip install openpyxl\n",
    "! pip install xgboost\n",
    "! pip install scikit-learn\n",
    "! pip install iteration_utilities\n",
    "! pip install ta\n",
    "! pip install MetaTrader5\n",
    "! pip install openpyxl\n",
    "! pip install seaborn\n",
    "! pip install plotly\n",
    "! pip install ffn\n",
    "! pip install quantstats\n",
    "! pip install scikit-optimize\n",
    "! pip install keras\n",
    "! pip install pandas_ta\n",
    "! pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196784d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-31T10:29:38.806014Z",
     "iopub.status.busy": "2023-12-31T10:29:38.805655Z",
     "iopub.status.idle": "2023-12-31T10:29:53.203310Z",
     "shell.execute_reply": "2023-12-31T10:29:53.202310Z"
    },
    "id": "Z7KTK2OD1_GB",
    "papermill": {
     "duration": 14.416778,
     "end_time": "2023-12-31T10:29:53.205728",
     "exception": false,
     "start_time": "2023-12-31T10:29:38.788950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------- Import packages\n",
    "# import MetaTrader5 as mt5\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Dropout\n",
    "# from keras.layers import Dense\n",
    "# import tensorflow.keras.wrappers\n",
    "from sklearn.feature_selection import RFECV\n",
    "import ta\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import norm\n",
    "from sklearn import neighbors\n",
    "import sys\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from IPython import display\n",
    "from skopt import BayesSearchCV\n",
    "import pandas as pd\n",
    "import plotly as pl\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from statistics import stdev\n",
    "from statistics import variance\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import warnings\n",
    "import plotly.graph_objs as go\n",
    "import quantstats as qs\n",
    "import plotly.subplots\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import urllib.request\n",
    "import re\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from iteration_utilities import deepflatten\n",
    "import pandas_ta as ta\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import RFE\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from keras.layers import LSTM, Dense\n",
    "import tensorflow\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import pandas as pd\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from scipy.stats import loguniform\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29726ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-31T10:29:53.239827Z",
     "iopub.status.busy": "2023-12-31T10:29:53.238713Z",
     "iopub.status.idle": "2023-12-31T10:29:53.245209Z",
     "shell.execute_reply": "2023-12-31T10:29:53.244286Z"
    },
    "id": "HMzuD0QV2Nch",
    "papermill": {
     "duration": 0.025538,
     "end_time": "2023-12-31T10:29:53.247232",
     "exception": false,
     "start_time": "2023-12-31T10:29:53.221694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------- Download data from ICMarket broker\n",
    "# ! open MT5 platform and run connection code. Then download data.\n",
    "\n",
    "# ------------ Account Info\n",
    "# mt5.initialize() # initiate metatrader5 platform\n",
    "# login= # username\n",
    "# password='' # password\n",
    "# server='ICMarketsSC-Demo' # server\n",
    "# mt5.login(login,password,server) # login\n",
    "\n",
    "# ------------ 4 hour frequency\n",
    "# start=datetime(2000,1,1) # start date\n",
    "# end=datetime(2023,9,30) # end date\n",
    "# df1_h=pd.DataFrame(mt5.copy_rates_range(\"EURUSD\",mt5.TIMEFRAME_H4,start,end)) #EURUSD data 4 hour\n",
    "# df3_h=pd.DataFrame(mt5.copy_rates_range(\"GBPUSD\",mt5.TIMEFRAME_H4,start,end)) #GBPUSD data 4 hour\n",
    "# df4_h=pd.DataFrame(mt5.copy_rates_range(\"USDCHF\",mt5.TIMEFRAME_H4,start,end)) #USDCHF data 4 hour\n",
    "# df5_h=pd.DataFrame(mt5.copy_rates_range(\"USDCAD\",mt5.TIMEFRAME_H4,start,end)) #USDCAD data 4 hour\n",
    "# df6_h=pd.DataFrame(mt5.copy_rates_range(\"AUDUSD\",mt5.TIMEFRAME_H4,start,end)) #AUDUSD data 4 hour\n",
    "# df7_h=pd.DataFrame(mt5.copy_rates_range(\"NZDUSD\",mt5.TIMEFRAME_H4,start,end)) #NZDUSD data 4 hour\n",
    "# for i,text in zip([df1_h, df3_h, df4_h, df5_h, df6_h, df7_h],[\"df1_h\", \"df3_h\", \"df4_h\", \"df5_h\", \"df6_h\", \"df7_h\"]): # loop for time variable\n",
    "#      i[\"time\"] = pd.to_datetime(i[\"time\"], unit=\"s\") # convert time to date\n",
    "#      print(len(i)) # number of observations\n",
    "#      i.to_pickle('data/'+text+\".pkl\") # save as pkl file\n",
    "\n",
    "# ------------ daily frequency \n",
    "# start=datetime(2000,1,1) # start date\n",
    "# end=datetime(2023,9,30) # end date\n",
    "# df1_d=pd.DataFrame(mt5.copy_rates_range(\"EURUSD\",mt5.TIMEFRAME_D1,start,end)) #EURUSD data daily\n",
    "# df3_d=pd.DataFrame(mt5.copy_rates_range(\"GBPUSD\",mt5.TIMEFRAME_D1,start,end)) #GBPUSD data daily\n",
    "# df4_d=pd.DataFrame(mt5.copy_rates_range(\"USDCHF\",mt5.TIMEFRAME_D1,start,end)) #USDCHF data daily\n",
    "# df5_d=pd.DataFrame(mt5.copy_rates_range(\"USDCAD\",mt5.TIMEFRAME_D1,start,end)) #USDCAD data daily\n",
    "# df6_d=pd.DataFrame(mt5.copy_rates_range(\"AUDUSD\",mt5.TIMEFRAME_D1,start,end)) #AUDUSD data daily\n",
    "# df7_d=pd.DataFrame(mt5.copy_rates_range(\"NZDUSD\",mt5.TIMEFRAME_D1,start,end)) #NZDUSD data daily\n",
    "# for i,text in zip([df1_d, df3_d, df4_d, df5_d, df6_d, df7_d],[\"df1_d\", \"df3_d\", \"df4_d\", \"df5_d\", \"df6_d\", \"df7_d\"]): # loop for time variable\n",
    "#      i[\"time\"] = pd.to_datetime(i[\"time\"], unit=\"s\") # convert time to date\n",
    "#      print(len(i)) # number of observations\n",
    "#      i.to_pickle('data/'+text+\".pkl\") # save as pkl file\n",
    "\n",
    "# mt5.shutdown() # shutdown metatrader5 platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d869880",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-31T10:29:53.315918Z",
     "iopub.status.busy": "2023-12-31T10:29:53.315272Z",
     "iopub.status.idle": "2023-12-31T10:29:53.357161Z",
     "shell.execute_reply": "2023-12-31T10:29:53.356385Z"
    },
    "id": "8XxrtKVo5ALH",
    "papermill": {
     "duration": 0.059651,
     "end_time": "2023-12-31T10:29:53.359175",
     "exception": false,
     "start_time": "2023-12-31T10:29:53.299524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>tick_volume</th>\n",
       "      <th>spread</th>\n",
       "      <th>real_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03 00:00:00</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>1.0175</td>\n",
       "      <td>670</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03 04:00:00</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>1.0181</td>\n",
       "      <td>1.0154</td>\n",
       "      <td>1.0157</td>\n",
       "      <td>609</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03 08:00:00</td>\n",
       "      <td>1.0154</td>\n",
       "      <td>1.0167</td>\n",
       "      <td>1.0093</td>\n",
       "      <td>1.0115</td>\n",
       "      <td>1731</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03 12:00:00</td>\n",
       "      <td>1.0118</td>\n",
       "      <td>1.0118</td>\n",
       "      <td>1.0054</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>1562</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    open    high     low   close  tick_volume  spread  \\\n",
       "0 2000-01-03 00:00:00  1.0073  1.0190  1.0073  1.0175          670      50   \n",
       "1 2000-01-03 04:00:00  1.0173  1.0181  1.0154  1.0157          609      50   \n",
       "2 2000-01-03 08:00:00  1.0154  1.0167  1.0093  1.0115         1731      50   \n",
       "3 2000-01-03 12:00:00  1.0118  1.0118  1.0054  1.0073         1562      50   \n",
       "\n",
       "   real_volume  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>tick_volume</th>\n",
       "      <th>spread</th>\n",
       "      <th>real_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>1.0278</td>\n",
       "      <td>1.0054</td>\n",
       "      <td>1.0246</td>\n",
       "      <td>6642</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>1.0243</td>\n",
       "      <td>1.0340</td>\n",
       "      <td>1.0213</td>\n",
       "      <td>1.0292</td>\n",
       "      <td>7339</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>1.0293</td>\n",
       "      <td>1.0402</td>\n",
       "      <td>1.0284</td>\n",
       "      <td>1.0326</td>\n",
       "      <td>6570</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>1.0325</td>\n",
       "      <td>1.0415</td>\n",
       "      <td>1.0272</td>\n",
       "      <td>1.0330</td>\n",
       "      <td>7223</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time    open    high     low   close  tick_volume  spread  real_volume\n",
       "0 2000-01-03  1.0073  1.0278  1.0054  1.0246         6642      50            0\n",
       "1 2000-01-04  1.0243  1.0340  1.0213  1.0292         7339      50            0\n",
       "2 2000-01-05  1.0293  1.0402  1.0284  1.0326         6570      50            0\n",
       "3 2000-01-06  1.0325  1.0415  1.0272  1.0330         7223      50            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------- Data import\n",
    "# ------------ Choose specific currency pair \n",
    "df1_h = pd.read_pickle('data/df1_h.pkl') # 4 hour frequency of chosen currency pair\n",
    "df1_d = pd.read_pickle('data/df1_d.pkl') # daily frequency of chosen currency pair\n",
    "\n",
    "display(df1_h.head(4))\n",
    "display(df1_d.head(4))\n",
    "\n",
    "name_list=['EURUSD'] # 'GBPUSD','USDCHF','USDCAD','AUDUSD','NZDUSD' # list of 6 currency pairs\n",
    "df_list_h=[df1_h]\n",
    "df_list_d=[df1_d]\n",
    "\n",
    "# -------- information pkl files\n",
    "# df1 - EURUSD\n",
    "# df3 - GBPUSD\n",
    "# df4 - USDCHF\n",
    "# df5 - USDCAD\n",
    "# df6 - AUDUSD\n",
    "# df7 - NZDUSD\n",
    "# !df2 - it is USDJPY price data. I didn't use it on my thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "103d04d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-31T10:29:53.391306Z",
     "iopub.status.busy": "2023-12-31T10:29:53.391005Z",
     "iopub.status.idle": "2023-12-31T10:29:53.404374Z",
     "shell.execute_reply": "2023-12-31T10:29:53.403515Z"
    },
    "id": "Y2skTdBzrJmo",
    "papermill": {
     "duration": 0.03179,
     "end_time": "2023-12-31T10:29:53.406349",
     "exception": false,
     "start_time": "2023-12-31T10:29:53.374559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>tick_volume</th>\n",
       "      <th>spread</th>\n",
       "      <th>real_volume</th>\n",
       "      <th>close_pre</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03 00:00:00</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>1.0175</td>\n",
       "      <td>670</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03 04:00:00</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>1.0181</td>\n",
       "      <td>1.0154</td>\n",
       "      <td>1.0157</td>\n",
       "      <td>609</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0175</td>\n",
       "      <td>-0.001769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03 08:00:00</td>\n",
       "      <td>1.0154</td>\n",
       "      <td>1.0167</td>\n",
       "      <td>1.0093</td>\n",
       "      <td>1.0115</td>\n",
       "      <td>1731</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0157</td>\n",
       "      <td>-0.004135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03 12:00:00</td>\n",
       "      <td>1.0118</td>\n",
       "      <td>1.0118</td>\n",
       "      <td>1.0054</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>1562</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0115</td>\n",
       "      <td>-0.004152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    open    high     low   close  tick_volume  spread  \\\n",
       "0 2000-01-03 00:00:00  1.0073  1.0190  1.0073  1.0175          670      50   \n",
       "1 2000-01-03 04:00:00  1.0173  1.0181  1.0154  1.0157          609      50   \n",
       "2 2000-01-03 08:00:00  1.0154  1.0167  1.0093  1.0115         1731      50   \n",
       "3 2000-01-03 12:00:00  1.0118  1.0118  1.0054  1.0073         1562      50   \n",
       "\n",
       "   real_volume  close_pre    return  \n",
       "0            0        NaN       NaN  \n",
       "1            0     1.0175 -0.001769  \n",
       "2            0     1.0157 -0.004135  \n",
       "3            0     1.0115 -0.004152  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>tick_volume</th>\n",
       "      <th>spread</th>\n",
       "      <th>real_volume</th>\n",
       "      <th>close_pre</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>1.0278</td>\n",
       "      <td>1.0054</td>\n",
       "      <td>1.0246</td>\n",
       "      <td>6642</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>1.0243</td>\n",
       "      <td>1.0340</td>\n",
       "      <td>1.0213</td>\n",
       "      <td>1.0292</td>\n",
       "      <td>7339</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0246</td>\n",
       "      <td>0.004490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>1.0293</td>\n",
       "      <td>1.0402</td>\n",
       "      <td>1.0284</td>\n",
       "      <td>1.0326</td>\n",
       "      <td>6570</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0292</td>\n",
       "      <td>0.003304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>1.0325</td>\n",
       "      <td>1.0415</td>\n",
       "      <td>1.0272</td>\n",
       "      <td>1.0330</td>\n",
       "      <td>7223</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0326</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time    open    high     low   close  tick_volume  spread  \\\n",
       "0 2000-01-03  1.0073  1.0278  1.0054  1.0246         6642      50   \n",
       "1 2000-01-04  1.0243  1.0340  1.0213  1.0292         7339      50   \n",
       "2 2000-01-05  1.0293  1.0402  1.0284  1.0326         6570      50   \n",
       "3 2000-01-06  1.0325  1.0415  1.0272  1.0330         7223      50   \n",
       "\n",
       "   real_volume  close_pre    return  \n",
       "0            0        NaN       NaN  \n",
       "1            0     1.0246  0.004490  \n",
       "2            0     1.0292  0.003304  \n",
       "3            0     1.0326  0.000387  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------- Return\n",
    "# Desc: I considered 2 different return methods. If I use simple return, run simple return code. If I use log return, run only log return code.\n",
    "for i,j in zip(df_list_h,df_list_d):\n",
    "    for a in [i,j]:\n",
    "        a['close_pre']=a.close.shift(1)\n",
    "        a['return']=(a['close']-a['close_pre'])/a['close_pre'] # calculating simple return using close price\n",
    "        # a['return'] = np.log(a['close']) - np.log(a['close_pre']) # calculating log return using close price\n",
    "display(df1_h.head(4))\n",
    "display(df1_d.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7072183a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-31T10:29:53.437793Z",
     "iopub.status.busy": "2023-12-31T10:29:53.437516Z",
     "iopub.status.idle": "2023-12-31T10:29:53.471946Z",
     "shell.execute_reply": "2023-12-31T10:29:53.471061Z"
    },
    "id": "n4N0d_BsB0S-",
    "papermill": {
     "duration": 0.052341,
     "end_time": "2023-12-31T10:29:53.473784",
     "exception": false,
     "start_time": "2023-12-31T10:29:53.421443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------- Functions\n",
    "\n",
    "# ------------ Technical Indicators\n",
    "\n",
    "### Trend following indicators\n",
    "\n",
    "def MA(pair,period,type_ma): # Simple and Exponential Moving Averages\n",
    "    if type_ma==\"sma\": \n",
    "        pair['sma'+str(period)]=pair['close'].rolling(period).mean()\n",
    "    elif type_ma==\"ema\": \n",
    "        pair['ema'+str(period)]=pair['close'].ewm(span=period).mean()\n",
    "\n",
    "def macd(pair,slow,fast,smooth): # Moving Average Convergence Divergence\n",
    "    pair['macd_slow']=pair['close'].ewm(span=fast).mean()-pair['close'].ewm(span=slow).mean()\n",
    "    pair['macd_fast']=pair['close'].ewm(span=smooth).mean()\n",
    "\n",
    "def adx(pair,period): # Average Directional Index\n",
    "    pair[['ADX_14','DMP_14','DMN_14']]=ta.adx(pair['high'],pair['low'],pair['close'],period)\n",
    "\n",
    "### Oscillator indicators\n",
    "\n",
    "def RSI(pair, periods): # Relative Strength Index\n",
    "    pair['rsi_up']=pair['close']-pair['close'].shift(1) #shift(1)-previous, shift(-1)-next\n",
    "    pair['rsi_down']=pair['close'].shift(1)-pair['close']\n",
    "    pair.loc[pair['rsi_up'] <= 0, 'rsi_up'] = 0\n",
    "    pair.loc[pair['rsi_down'] <= 0, 'rsi_down'] = 0\n",
    "    pair['rsi_up_avg']=pair['rsi_up'].rolling(periods).mean()#.apply(lambda x: x[x!= 0].mean())\n",
    "    pair['rsi_down_avg']=pair['rsi_down'].rolling(periods).mean()#.apply(lambda x: x[x!= 0].mean())\n",
    "    for i in range(periods+1,len(pair)):\n",
    "        pair['rsi_up_avg'][i]=(pair['rsi_up_avg'][i-1]*(periods-1)+pair['rsi_up'][i])/periods\n",
    "        pair['rsi_down_avg'][i]=(pair['rsi_down_avg'][i-1]*(periods-1)+pair['rsi_down'][i])/periods\n",
    "    pair['rsi_rs']=pair['rsi_up_avg']/pair[\"rsi_down_avg\"]\n",
    "    pair['rsi']=100-(100/(1+pair['rsi_rs']))\n",
    "\n",
    "def Stochastic(pair,k_period,d_period): # Stochastic Oscillator\n",
    "    pair['sto_dif1']=pair['close']-pair['low'].rolling(k_period).min()\n",
    "    pair['sto_dif2']=pair['high'].rolling(k_period).max()-pair['low'].rolling(k_period).min()\n",
    "    pair['sto_k']=pair['sto_dif1']/pair['sto_dif2']*100\n",
    "    pair['sto_main']=pair['sto_dif1'].rolling(d_period).sum()/pair['sto_dif2'].rolling(d_period).sum()*100\n",
    "    pair['sto_signal']=pair['sto_main'].rolling(d_period).mean()\n",
    "\n",
    "def cci(pair,cci_sma,cci_num): # Commodity Channel Index\n",
    "    cci_num=0.015\n",
    "    pair['typ.price']=(pair['high']+pair['low']+pair['close'])/3\n",
    "    pair['cci']=(pair['typ.price']-pair['typ.price'].rolling(cci_sma).mean())/(cci_num*stdev(pair['typ.price']))\n",
    "\n",
    "def willr(pair,period): # Williams R\n",
    "    pair['willr']=ta.willr(pair['high'],pair['low'],pair['close'],period)\n",
    "\n",
    "### Volatility indicators\n",
    "\n",
    "def BB(pair,avgday,stdmul): # Bollinger Band\n",
    "    pair['bb_std']=pair['close'].rolling(avgday).std()\n",
    "    pair['bb_mid']=pair['close'].rolling(avgday).mean()\n",
    "    pair['bb_down']=pair['bb_mid']-pair['bb_std']*stdmul\n",
    "    pair['bb_up']=pair['bb_mid']+pair['bb_std']*stdmul\n",
    "\n",
    "def atr(pair,period): # Average True Range\n",
    "    pair['atr']=ta.atr(pair['high'],pair['low'],pair['close'],period)\n",
    "\n",
    "# ------------ Performance metrics\n",
    "def ASD(return_in): # Annual standart deviation\n",
    "  var_output=return_in.var()\n",
    "  var_output=var_output*252**(1/2) # 4hour - 1512\n",
    "  return var_output\n",
    "\n",
    "def calculate_sharpe_ratio(return_series,rf): # Sharpe ratio #255, #0.01\n",
    "    x=return_series-rf\n",
    "    mean=x.mean()\n",
    "    sigma = return_series.std()\n",
    "    return mean / sigma\n",
    "\n",
    "def calculate_roi(equity): # Return on Investment (ROI)\n",
    "  x=(equity.iloc[-1]-equity.iloc[0])/equity.iloc[0]\n",
    "  return x\n",
    "\n",
    "def calculate_max_drawdown(returns):\n",
    "    cum_returns = (1 + returns).cumprod()\n",
    "    rolling_max = cum_returns.cummax()\n",
    "    drawdown = (cum_returns / rolling_max) - 1\n",
    "    max_drawdown = drawdown.min()\n",
    "    return max_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ca02157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-31T10:29:53.542029Z",
     "iopub.status.busy": "2023-12-31T10:29:53.541754Z",
     "iopub.status.idle": "2023-12-31T10:30:24.869293Z",
     "shell.execute_reply": "2023-12-31T10:30:24.868036Z"
    },
    "id": "1fjT9QbZrJmp",
    "papermill": {
     "duration": 31.34657,
     "end_time": "2023-12-31T10:30:24.872259",
     "exception": false,
     "start_time": "2023-12-31T10:29:53.525689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>close_pre</th>\n",
       "      <th>return</th>\n",
       "      <th>ema10</th>\n",
       "      <th>ema20</th>\n",
       "      <th>ema50</th>\n",
       "      <th>...</th>\n",
       "      <th>cci</th>\n",
       "      <th>willr</th>\n",
       "      <th>bb_mid</th>\n",
       "      <th>bb_down</th>\n",
       "      <th>bb_up</th>\n",
       "      <th>atr</th>\n",
       "      <th>momentum</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>range</th>\n",
       "      <th>ohlc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36980</th>\n",
       "      <td>2023-09-29 08:00:00</td>\n",
       "      <td>1.05801</td>\n",
       "      <td>1.06162</td>\n",
       "      <td>1.05743</td>\n",
       "      <td>1.06091</td>\n",
       "      <td>1.05801</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>1.056204</td>\n",
       "      <td>1.056581</td>\n",
       "      <td>1.060446</td>\n",
       "      <td>...</td>\n",
       "      <td>1.899571</td>\n",
       "      <td>-5.542545</td>\n",
       "      <td>1.055501</td>\n",
       "      <td>1.048624</td>\n",
       "      <td>1.062377</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>-0.00290</td>\n",
       "      <td>1.059525</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>1.059493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36981</th>\n",
       "      <td>2023-09-29 12:00:00</td>\n",
       "      <td>1.06087</td>\n",
       "      <td>1.06170</td>\n",
       "      <td>1.05883</td>\n",
       "      <td>1.05997</td>\n",
       "      <td>1.06091</td>\n",
       "      <td>-0.000886</td>\n",
       "      <td>1.056889</td>\n",
       "      <td>1.056903</td>\n",
       "      <td>1.060427</td>\n",
       "      <td>...</td>\n",
       "      <td>1.946463</td>\n",
       "      <td>-13.421257</td>\n",
       "      <td>1.055535</td>\n",
       "      <td>1.048572</td>\n",
       "      <td>1.062499</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.00090</td>\n",
       "      <td>1.060265</td>\n",
       "      <td>0.00287</td>\n",
       "      <td>1.060342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36982</th>\n",
       "      <td>2023-09-29 16:00:00</td>\n",
       "      <td>1.05997</td>\n",
       "      <td>1.06074</td>\n",
       "      <td>1.05700</td>\n",
       "      <td>1.05777</td>\n",
       "      <td>1.05997</td>\n",
       "      <td>-0.002076</td>\n",
       "      <td>1.057049</td>\n",
       "      <td>1.056986</td>\n",
       "      <td>1.060323</td>\n",
       "      <td>...</td>\n",
       "      <td>1.254582</td>\n",
       "      <td>-30.488751</td>\n",
       "      <td>1.055444</td>\n",
       "      <td>1.048660</td>\n",
       "      <td>1.062228</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.00220</td>\n",
       "      <td>1.058870</td>\n",
       "      <td>0.00374</td>\n",
       "      <td>1.058870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36983</th>\n",
       "      <td>2023-09-29 20:00:00</td>\n",
       "      <td>1.05776</td>\n",
       "      <td>1.05796</td>\n",
       "      <td>1.05640</td>\n",
       "      <td>1.05732</td>\n",
       "      <td>1.05777</td>\n",
       "      <td>-0.000425</td>\n",
       "      <td>1.057098</td>\n",
       "      <td>1.057018</td>\n",
       "      <td>1.060205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779076</td>\n",
       "      <td>-33.979829</td>\n",
       "      <td>1.055281</td>\n",
       "      <td>1.048870</td>\n",
       "      <td>1.061692</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>1.057180</td>\n",
       "      <td>0.00156</td>\n",
       "      <td>1.057360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time     open     high      low    close  close_pre  \\\n",
       "36980 2023-09-29 08:00:00  1.05801  1.06162  1.05743  1.06091    1.05801   \n",
       "36981 2023-09-29 12:00:00  1.06087  1.06170  1.05883  1.05997    1.06091   \n",
       "36982 2023-09-29 16:00:00  1.05997  1.06074  1.05700  1.05777    1.05997   \n",
       "36983 2023-09-29 20:00:00  1.05776  1.05796  1.05640  1.05732    1.05777   \n",
       "\n",
       "         return     ema10     ema20     ema50  ...       cci      willr  \\\n",
       "36980  0.002741  1.056204  1.056581  1.060446  ...  1.899571  -5.542545   \n",
       "36981 -0.000886  1.056889  1.056903  1.060427  ...  1.946463 -13.421257   \n",
       "36982 -0.002076  1.057049  1.056986  1.060323  ...  1.254582 -30.488751   \n",
       "36983 -0.000425  1.057098  1.057018  1.060205  ...  0.779076 -33.979829   \n",
       "\n",
       "         bb_mid   bb_down     bb_up       atr  momentum  avg_price    range  \\\n",
       "36980  1.055501  1.048624  1.062377  0.002772  -0.00290   1.059525  0.00419   \n",
       "36981  1.055535  1.048572  1.062499  0.002779   0.00090   1.060265  0.00287   \n",
       "36982  1.055444  1.048660  1.062228  0.002848   0.00220   1.058870  0.00374   \n",
       "36983  1.055281  1.048870  1.061692  0.002756   0.00044   1.057180  0.00156   \n",
       "\n",
       "           ohlc  \n",
       "36980  1.059493  \n",
       "36981  1.060342  \n",
       "36982  1.058870  \n",
       "36983  1.057360  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>close_pre</th>\n",
       "      <th>return</th>\n",
       "      <th>ema10</th>\n",
       "      <th>ema20</th>\n",
       "      <th>ema50</th>\n",
       "      <th>...</th>\n",
       "      <th>cci</th>\n",
       "      <th>willr</th>\n",
       "      <th>bb_mid</th>\n",
       "      <th>bb_down</th>\n",
       "      <th>bb_up</th>\n",
       "      <th>atr</th>\n",
       "      <th>momentum</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>range</th>\n",
       "      <th>ohlc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6168</th>\n",
       "      <td>2023-09-26</td>\n",
       "      <td>1.05931</td>\n",
       "      <td>1.06090</td>\n",
       "      <td>1.05622</td>\n",
       "      <td>1.05719</td>\n",
       "      <td>1.05921</td>\n",
       "      <td>-0.001907</td>\n",
       "      <td>1.065073</td>\n",
       "      <td>1.070418</td>\n",
       "      <td>1.080069</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.761669</td>\n",
       "      <td>-95.298110</td>\n",
       "      <td>1.071122</td>\n",
       "      <td>1.054616</td>\n",
       "      <td>1.087627</td>\n",
       "      <td>0.006612</td>\n",
       "      <td>0.00212</td>\n",
       "      <td>1.05856</td>\n",
       "      <td>0.00468</td>\n",
       "      <td>1.058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6169</th>\n",
       "      <td>2023-09-27</td>\n",
       "      <td>1.05717</td>\n",
       "      <td>1.05741</td>\n",
       "      <td>1.04881</td>\n",
       "      <td>1.05031</td>\n",
       "      <td>1.05719</td>\n",
       "      <td>-0.006508</td>\n",
       "      <td>1.062388</td>\n",
       "      <td>1.068503</td>\n",
       "      <td>1.078902</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.442492</td>\n",
       "      <td>-94.650499</td>\n",
       "      <td>1.069021</td>\n",
       "      <td>1.053196</td>\n",
       "      <td>1.084846</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.00686</td>\n",
       "      <td>1.05311</td>\n",
       "      <td>0.00860</td>\n",
       "      <td>1.053425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6170</th>\n",
       "      <td>2023-09-28</td>\n",
       "      <td>1.05009</td>\n",
       "      <td>1.05788</td>\n",
       "      <td>1.04912</td>\n",
       "      <td>1.05661</td>\n",
       "      <td>1.05031</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>1.061338</td>\n",
       "      <td>1.067371</td>\n",
       "      <td>1.078028</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.761178</td>\n",
       "      <td>-72.182596</td>\n",
       "      <td>1.067632</td>\n",
       "      <td>1.052630</td>\n",
       "      <td>1.082635</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>-0.00652</td>\n",
       "      <td>1.05350</td>\n",
       "      <td>0.00876</td>\n",
       "      <td>1.053425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>2023-09-29</td>\n",
       "      <td>1.05645</td>\n",
       "      <td>1.06170</td>\n",
       "      <td>1.05550</td>\n",
       "      <td>1.05732</td>\n",
       "      <td>1.05661</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>1.060607</td>\n",
       "      <td>1.066413</td>\n",
       "      <td>1.077216</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.753038</td>\n",
       "      <td>-69.650499</td>\n",
       "      <td>1.066631</td>\n",
       "      <td>1.051685</td>\n",
       "      <td>1.081577</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>-0.00087</td>\n",
       "      <td>1.05860</td>\n",
       "      <td>0.00620</td>\n",
       "      <td>1.057743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time     open     high      low    close  close_pre    return  \\\n",
       "6168 2023-09-26  1.05931  1.06090  1.05622  1.05719    1.05921 -0.001907   \n",
       "6169 2023-09-27  1.05717  1.05741  1.04881  1.05031    1.05719 -0.006508   \n",
       "6170 2023-09-28  1.05009  1.05788  1.04912  1.05661    1.05031  0.005998   \n",
       "6171 2023-09-29  1.05645  1.06170  1.05550  1.05732    1.05661  0.000672   \n",
       "\n",
       "         ema10     ema20     ema50  ...       cci      willr    bb_mid  \\\n",
       "6168  1.065073  1.070418  1.080069  ... -5.761669 -95.298110  1.071122   \n",
       "6169  1.062388  1.068503  1.078902  ... -7.442492 -94.650499  1.069021   \n",
       "6170  1.061338  1.067371  1.078028  ... -5.761178 -72.182596  1.067632   \n",
       "6171  1.060607  1.066413  1.077216  ... -3.753038 -69.650499  1.066631   \n",
       "\n",
       "       bb_down     bb_up       atr  momentum  avg_price    range      ohlc  \n",
       "6168  1.054616  1.087627  0.006612   0.00212    1.05856  0.00468  1.058405  \n",
       "6169  1.053196  1.084846  0.006754   0.00686    1.05311  0.00860  1.053425  \n",
       "6170  1.052630  1.082635  0.006897  -0.00652    1.05350  0.00876  1.053425  \n",
       "6171  1.051685  1.081577  0.006847  -0.00087    1.05860  0.00620  1.057743  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------- Applying Technical Indicators (default settings)\n",
    "for i,j in zip(df_list_h,df_list_d):\n",
    "     for a in [i,j]:\n",
    "         # Trend following indicators\n",
    "         MA(a,10,'ema') # EMA(10)\n",
    "         MA(a,20,'ema') # EMA(20)\n",
    "         MA(a,50,\"ema\") # EMA(50)\n",
    "         MA(a,100,\"ema\") # EMA(100)\n",
    "         MA(a,200,\"ema\") # EMA(200)\n",
    "         macd(a,26,12,9) # MACD(26, 12, 9)\n",
    "         adx(a,14) # ADX(14)\n",
    "         # Oscillator indicators\n",
    "         RSI(a, 14) # RSI(14)\n",
    "         Stochastic(a,14,3) # Stoch(14,3,3)\n",
    "         cci(a,20,0.015) # CCI(20, 0.015)\n",
    "         willr(a,14) # WilliamR(14)\n",
    "         # Volatility indicators\n",
    "         BB(a,20,2) # BB(20,2)\n",
    "         atr(a,14) # ATR(14)\n",
    "         a=a.drop(columns=['sto_dif1', 'sto_dif2','tick_volume', 'spread', # removing unnecessary columns\n",
    "                           'real_volume','rsi_up', 'rsi_down', 'rsi_up_avg', 'rsi_down_avg',\n",
    "                           'rsi_rs','sto_k','bb_std','typ.price'], axis=1, inplace=True) \n",
    "\n",
    "# ---------------------------------- Applying Statistical Indicators (additional)\n",
    "for i,j in zip(df_list_h,df_list_d):\n",
    "  for a in [i,j]:\n",
    "    a['momentum']=a['open']-a['close'] # Momentum\n",
    "    a['avg_price']=(a['low']+a['high'])/2 # AVG\n",
    "    a['range']=a['high']-a['low'] # Range\n",
    "    a['ohlc']=(a['open']+a['close']+a['low']+a['high'])/4 # OHLC\n",
    "\n",
    "display(df1_h.tail(4))\n",
    "display(df1_d.tail(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abbc8e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-31T10:30:24.952311Z",
     "iopub.status.busy": "2023-12-31T10:30:24.952047Z",
     "iopub.status.idle": "2023-12-31T10:30:24.977312Z",
     "shell.execute_reply": "2023-12-31T10:30:24.976628Z"
    },
    "id": "QMeCqo0gCFqF",
    "papermill": {
     "duration": 0.043346,
     "end_time": "2023-12-31T10:30:24.979197",
     "exception": false,
     "start_time": "2023-12-31T10:30:24.935851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------- Machine Learning Models\n",
    "def all_model(model_name):\n",
    "     # ------- Ridge Regression\n",
    "     if model_name=='RIDGE':\n",
    "        model = Ridge()\n",
    "        # ------- hyperparameters\n",
    "        param_grid = {'alpha': uniform(0.00001, 1.0)}\n",
    "     elif model_name=='SVM': \n",
    "        model = SVR()\n",
    "        param_grid = {'kernel': ['linear', 'rbf','poly'],\n",
    "                      'C': loguniform(0.1, 10), \n",
    "                      'gamma': uniform(0.1, 10), \n",
    "                      'degree':randint(1,4)}\n",
    "     # ------- K Nearest Neighbors\n",
    "     elif model_name=='KNN': \n",
    "        model = neighbors.KNeighborsRegressor() \n",
    "        # ------- hyperparameters\n",
    "        param_grid = {\n",
    "            'n_neighbors': randint(1,20), \n",
    "            'p': [1,3]\n",
    "            }\n",
    "     # ------- Random Forest\n",
    "     elif model_name=='RF':\n",
    "        model = RandomForestRegressor() \n",
    "        # ------- hyperparameters\n",
    "        param_grid = {'n_estimators':randint(20, 200), \n",
    "                      'max_features': randint(5,30), \n",
    "                      'max_depth':randint(1,6), \n",
    "                      'min_samples_split':randint(2,30)} \n",
    "     # ------- Extreme Gradient Boosting\n",
    "     elif model_name=='XGBOOST': \n",
    "        model=xgb.XGBRegressor() \n",
    "        # ------- hyperparameters\n",
    "        param_grid = {'n_estimators':randint(20, 200), \n",
    "                      'learning_rate':loguniform(0.001,0.5),\n",
    "                      'max_depth':randint(8,15),\n",
    "                      'gamma':uniform(0.001,0.02),\n",
    "                      }\n",
    "     # ------- Gradient Boosting Decision Tree\n",
    "     elif model_name=='GBDT':\n",
    "        model = GradientBoostingRegressor()\n",
    "        # ------- hyperparameters\n",
    "        param_grid = {'n_estimators':randint(20, 200),\n",
    "                      'learning_rate':loguniform(0.0001,0.5),\n",
    "                      'max_depth':randint(1,5)}\n",
    "     # ------- Artificial Neural Network\n",
    "     elif model_name=='ANN':\n",
    "        def create_model(model__neurons=5,optimizer='sgd',model__hidden_layers=1,activation = 'tanh', optimizer__momentum=0.2,dropout_rate=0.2,optimizer__learning_rate=0.01,**kwargs):\n",
    "          model = Sequential()\n",
    "          model.add(Dense(units=X_train.shape[1], input_dim=X_train.shape[1], activation=activation))\n",
    "          for _ in range(model__hidden_layers):\n",
    "            model.add(Dropout(dropout_rate))\n",
    "            model.add(Dense(units=model__neurons, activation=activation))\n",
    "          model.add(Dropout(dropout_rate))\n",
    "          model.add(Dense(1))\n",
    "          if optimizer == 'sgd':\n",
    "            optimizer = keras.optimizers.SGD(learning_rate=optimizer__learning_rate, momentum=optimizer__momentum)\n",
    "          elif optimizer == 'rmsprop':\n",
    "            optimizer = keras.optimizers.RMSprop(learning_rate=optimizer__learning_rate)\n",
    "          model.compile(loss='mean_absolute_error', optimizer=optimizer,metrics=['mae'])\n",
    "          return model\n",
    "        model = KerasRegressor(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
    "        # ------- hyperparameters\n",
    "        param_grid = {\n",
    "            'model__hidden_layers': randint(1, 3),\n",
    "            'optimizer': ['sgd', 'rmsprop'],\n",
    "            'optimizer__learning_rate': loguniform(0.001,  0.05),\n",
    "            'optimizer__momentum': uniform(0.1, 0.4),\n",
    "            'batch_size': [64, 128],\n",
    "            'epochs': [20,30],\n",
    "            'model__neurons': randint(5,40)\n",
    "        }\n",
    "     # ------- Gated Recurrent Units\n",
    "     elif model_name=='GRU':\n",
    "        def create_gru_model(model__neurons=5,optimizer='sgd',model__hidden_layers=1,activation = 'tanh', optimizer__momentum=0.2,dropout_rate=0.2,optimizer__learning_rate=0.01,**kwargs):\n",
    "          model = Sequential()\n",
    "          model.add(GRU(units=X_train.shape[1], return_sequences = True, input_shape=(X_train.shape[1], 1),activation=activation))\n",
    "          for _ in range(model__hidden_layers):\n",
    "                      model.add(GRU(units=model__neurons, return_sequences = True,dropout=dropout_rate,activation=activation))\n",
    "          model.add(Dense(1))\n",
    "          if optimizer == 'sgd':\n",
    "            optimizer = keras.optimizers.SGD(learning_rate=optimizer__learning_rate, momentum=optimizer__momentum)\n",
    "          elif optimizer == 'rmsprop':\n",
    "            optimizer = keras.optimizers.RMSprop(learning_rate=optimizer__learning_rate)\n",
    "          model.compile(loss='mean_absolute_error', optimizer=optimizer,metrics=['mae'])\n",
    "          return model\n",
    "        model = KerasRegressor(build_fn=create_gru_model, epochs=10, batch_size=32, verbose=0)\n",
    "        # ------- hyperparameters\n",
    "        param_grid = {\n",
    "            'model__hidden_layers': randint(1, 3),\n",
    "            'optimizer': ['sgd', 'rmsprop'],\n",
    "            'optimizer__learning_rate': loguniform(0.001,  0.05),\n",
    "            'optimizer__momentum': uniform(0.1, 0.4),\n",
    "            'batch_size': [64, 128],\n",
    "            'epochs': [20,30],\n",
    "            'model__neurons': randint(5,40)\n",
    "        }\n",
    "     # ------- Long Short Term Memory\n",
    "     elif model_name=='LSTM':\n",
    "        def create_lstm_model(model__neurons=5,optimizer='sgd',model__hidden_layers=1,activation = 'tanh', optimizer__momentum=0.2,dropout_rate=0.2,optimizer__learning_rate=0.01,**kwargs):\n",
    "          model = Sequential()\n",
    "          model.add(LSTM(units=X_train.shape[1], return_sequences = True, input_shape=(X_train.shape[1], 1),activation=activation))\n",
    "          for _ in range(model__hidden_layers):\n",
    "                      model.add(LSTM(units=model__neurons, return_sequences = True,dropout=dropout_rate,activation=activation))\n",
    "          model.add(Dense(1))\n",
    "          if optimizer == 'sgd':\n",
    "            optimizer = keras.optimizers.SGD(learning_rate=optimizer__learning_rate, momentum=optimizer__momentum)\n",
    "          elif optimizer == 'rmsprop':\n",
    "            optimizer = keras.optimizers.RMSprop(learning_rate=optimizer__learning_rate)\n",
    "          model.compile(loss='mean_absolute_error', optimizer=optimizer,metrics=['mae'])\n",
    "          return model\n",
    "        model = KerasRegressor(build_fn=create_lstm_model, epochs=10, batch_size=32, verbose=0)\n",
    "        # ------- hyperparameters\n",
    "        param_grid = {\n",
    "            'model__hidden_layers': randint(1, 3),\n",
    "            'optimizer': ['sgd', 'rmsprop'],\n",
    "            'optimizer__learning_rate': loguniform(0.001,  0.05),\n",
    "            'optimizer__momentum': uniform(0.1, 0.4),\n",
    "            'batch_size': [64, 128],\n",
    "            'epochs': [20,30],\n",
    "            'model__neurons': randint(5,40)\n",
    "        }\n",
    "     return model, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e1384b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-31T10:30:25.011157Z",
     "iopub.status.busy": "2023-12-31T10:30:25.010839Z",
     "iopub.status.idle": "2023-12-31T18:35:28.513890Z",
     "shell.execute_reply": "2023-12-31T18:35:28.512892Z"
    },
    "executionInfo": {
     "elapsed": 2468942,
     "status": "ok",
     "timestamp": 1701611605963,
     "user": {
      "displayName": "Sugarbayar Enkhbayar",
      "userId": "11356332751747853171"
     },
     "user_tz": -60
    },
    "id": "l9Az3TdnrJmr",
    "outputId": "e94d3d3d-c1ac-4724-98a4-55b9a68c36ec",
    "papermill": {
     "duration": 29103.522158,
     "end_time": "2023-12-31T18:35:28.516510",
     "exception": false,
     "start_time": "2023-12-31T10:30:24.994352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RIDGE   Window: 0\n",
      "Model: SVM   Window: 0\n",
      "Model: KNN   Window: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"c:\\Users\\sugar\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 217, in _count_physical_cores\n",
      "    raise ValueError(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RF   Window: 0\n",
      "Model: XGBOOST   Window: 0\n",
      "Model: GBDT   Window: 0\n",
      "Model: ANN   Window: 0\n",
      "WARNING:tensorflow:5 out of the last 20 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002D4450F1E40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002D4463FBEC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Model: LSTM   Window: 0\n",
      "Model: GRU   Window: 0\n",
      "                                         RIDGE                  SVM  \\\n",
      "start_date                 2003-01-01 00:00:00  2003-01-01 00:00:00   \n",
      "end_date                   2003-06-30 00:00:00  2003-06-30 00:00:00   \n",
      "Start                                     1000                 1000   \n",
      "End                                  998.84084                 1000   \n",
      "Gross profit                           5.26656                    0   \n",
      "Gross loss                            -6.42572                    0   \n",
      "Total Net profit                      -1.15916                    0   \n",
      "Return on initial capital                -0.1%                 0.0%   \n",
      "Profit factor                        -0.819606                  NaN   \n",
      "Total number of trades                      52                    0   \n",
      "%sell                                    46.2%                 nan%   \n",
      "%buy                                     53.8%                 nan%   \n",
      "Winning trades                              24                    0   \n",
      "Lossing trades                              27                    0   \n",
      "%profitable                              46.2%                 nan%   \n",
      "Avg.Trade Net profit                 -0.022292                  NaN   \n",
      "Avg.Winning trade                      0.21944                  NaN   \n",
      "Avg.Lossing trade                     -0.23799                  NaN   \n",
      "Ratio Avg.Win:Avg.Loss               -0.922057                  NaN   \n",
      "Largest Winning trade                  0.41682                    0   \n",
      "Largest Lossing trade                 -0.37986                    0   \n",
      "Cost                                  11.56176                    0   \n",
      "MD                                   -0.002122                  0.0   \n",
      "IR/SR                                -0.062725                  NaN   \n",
      "ROI                                  -0.001159                  0.0   \n",
      "MAE                                   0.001191             0.005229   \n",
      "\n",
      "                                           KNN                   RF  \\\n",
      "start_date                 2003-01-01 00:00:00  2003-01-01 00:00:00   \n",
      "end_date                   2003-06-30 00:00:00  2003-06-30 00:00:00   \n",
      "Start                                     1000                 1000   \n",
      "End                                 1000.22088            998.23264   \n",
      "Gross profit                           1.69898              5.15046   \n",
      "Gross loss                             -1.4781             -6.91782   \n",
      "Total Net profit                       0.22088             -1.76736   \n",
      "Return on initial capital                 0.0%                -0.2%   \n",
      "Profit factor                        -1.149435            -0.744521   \n",
      "Total number of trades                      13                   53   \n",
      "%sell                                    53.8%                43.4%   \n",
      "%buy                                     46.2%                56.6%   \n",
      "Winning trades                               7                   23   \n",
      "Lossing trades                               6                   29   \n",
      "%profitable                              53.8%                43.4%   \n",
      "Avg.Trade Net profit                  0.016991            -0.033346   \n",
      "Avg.Winning trade                     0.242711             0.223933   \n",
      "Avg.Lossing trade                     -0.24635            -0.238546   \n",
      "Ratio Avg.Win:Avg.Loss                -0.98523            -0.938743   \n",
      "Largest Winning trade                   0.2609              0.41682   \n",
      "Largest Lossing trade                 -0.37986             -0.37986   \n",
      "Cost                                   2.90208             11.80576   \n",
      "MD                                   -0.000959             -0.00273   \n",
      "IR/SR                                  0.02235            -0.094001   \n",
      "ROI                                   0.000221            -0.001767   \n",
      "MAE                                   0.003894             0.001292   \n",
      "\n",
      "                                       XGBOOST                 GBDT  \\\n",
      "start_date                 2003-01-01 00:00:00  2003-01-01 00:00:00   \n",
      "end_date                   2003-06-30 00:00:00  2003-06-30 00:00:00   \n",
      "Start                                     1000                 1000   \n",
      "End                                  998.76926            998.20932   \n",
      "Gross profit                           4.65846              5.08814   \n",
      "Gross loss                             -5.8892             -6.87882   \n",
      "Total Net profit                      -1.23074             -1.79068   \n",
      "Return on initial capital                -0.1%                -0.2%   \n",
      "Profit factor                        -0.791017            -0.739682   \n",
      "Total number of trades                      49                   53   \n",
      "%sell                                    46.9%                43.4%   \n",
      "%buy                                     53.1%                56.6%   \n",
      "Winning trades                              23                   23   \n",
      "Lossing trades                              25                   29   \n",
      "%profitable                              46.9%                43.4%   \n",
      "Avg.Trade Net profit                 -0.025117            -0.033786   \n",
      "Avg.Winning trade                     0.202542             0.221223   \n",
      "Avg.Lossing trade                    -0.235568            -0.237201   \n",
      "Ratio Avg.Win:Avg.Loss               -0.859802            -0.932643   \n",
      "Largest Winning trade                  0.41682              0.41682   \n",
      "Largest Lossing trade                 -0.37986             -0.37986   \n",
      "Cost                                  10.91514             11.82444   \n",
      "MD                                   -0.002326            -0.002886   \n",
      "IR/SR                                -0.069352            -0.095211   \n",
      "ROI                                  -0.001231            -0.001791   \n",
      "MAE                                   0.001164             0.001092   \n",
      "\n",
      "                                           ANN                 LSTM  \\\n",
      "start_date                 2003-01-01 00:00:00  2003-01-01 00:00:00   \n",
      "end_date                   2003-06-30 00:00:00  2003-06-30 00:00:00   \n",
      "Start                                     1000                 1000   \n",
      "End                                  1000.8944            999.74122   \n",
      "Gross profit                             4.289              3.50556   \n",
      "Gross loss                             -3.3946             -3.76434   \n",
      "Total Net profit                        0.8944             -0.25878   \n",
      "Return on initial capital                 0.1%                -0.0%   \n",
      "Profit factor                        -1.263477            -0.931255   \n",
      "Total number of trades                       1                   11   \n",
      "%sell                                     0.0%                45.5%   \n",
      "%buy                                    100.0%                54.5%   \n",
      "Winning trades                               0                    5   \n",
      "Lossing trades                               1                    6   \n",
      "%profitable                               0.0%                45.5%   \n",
      "Avg.Trade Net profit                    0.8944            -0.023525   \n",
      "Avg.Winning trade                          inf             0.701112   \n",
      "Avg.Lossing trade                      -3.3946             -0.62739   \n",
      "Ratio Avg.Win:Avg.Loss                    -inf            -1.117506   \n",
      "Largest Winning trade                    0.215              0.37986   \n",
      "Largest Lossing trade                  -0.3226              -0.3168   \n",
      "Cost                                    0.2096               2.4379   \n",
      "MD                                   -0.000549            -0.000931   \n",
      "IR/SR                                 0.129404            -0.022817   \n",
      "ROI                                   0.001217            -0.000259   \n",
      "MAE                                   0.035016             0.008362   \n",
      "\n",
      "                                           GRU  \n",
      "start_date                 2003-01-01 00:00:00  \n",
      "end_date                   2003-06-30 00:00:00  \n",
      "Start                                     1000  \n",
      "End                                   998.8653  \n",
      "Gross profit                           3.03512  \n",
      "Gross loss                            -4.16982  \n",
      "Total Net profit                       -1.1347  \n",
      "Return on initial capital                -0.1%  \n",
      "Profit factor                        -0.727878  \n",
      "Total number of trades                      21  \n",
      "%sell                                    28.6%  \n",
      "%buy                                     71.4%  \n",
      "Winning trades                               6  \n",
      "Lossing trades                              15  \n",
      "%profitable                              28.6%  \n",
      "Avg.Trade Net profit                 -0.054033  \n",
      "Avg.Winning trade                     0.505853  \n",
      "Avg.Lossing trade                    -0.277988  \n",
      "Ratio Avg.Win:Avg.Loss               -1.819695  \n",
      "Largest Winning trade                   0.3226  \n",
      "Largest Lossing trade                 -0.35918  \n",
      "Cost                                   4.64494  \n",
      "MD                                   -0.001403  \n",
      "IR/SR                                -0.115597  \n",
      "ROI                                  -0.001457  \n",
      "MAE                                   0.007104  \n"
     ]
    }
   ],
   "source": [
    "i=df1_d # choose currency pair\n",
    "\n",
    "# ---------------------------------- Rolling Walk Forward Approach\n",
    "\n",
    "# ------- parameters\n",
    "daily_range=600 # train set - daily=600, 4 hour=3600\n",
    "start_train=datetime(2000,1,1) # train and validation set - 3 year\n",
    "end_train=datetime(2002,12,31)\n",
    "start_test=datetime(2003,1,1) # test set - 6 months\n",
    "end_test=datetime(2003,6,30)\n",
    "is_oos=[[start_train,end_train,start_test,end_test]] # start date\n",
    "\n",
    "# ------- define date ranges of windows\n",
    "for j in range(2000):\n",
    "    start_train=is_oos[j][0]+relativedelta(months=+6)\n",
    "    end_train=is_oos[j][1]+relativedelta(months=+6)\n",
    "    end_train=end_train+ relativedelta(day=31)\n",
    "    start_test=is_oos[j][2]+relativedelta(months=+6)\n",
    "    end_test=is_oos[j][3]+relativedelta(months=+6)\n",
    "    end_test=end_test+ relativedelta(day=31)\n",
    "    if end_test>datetime(2023,9,30):\n",
    "        break\n",
    "    is_oos.append([start_train,end_train,start_test,end_test])\n",
    "\n",
    "# ------- define row index using date ranges\n",
    "is_oos_index=[]\n",
    "for z in is_oos:\n",
    "    train=i[(i.time>=z[0]) & (i.time<=z[1])].index.values.tolist()\n",
    "    test=i[(i.time>=z[2]) & (i.time<=z[3])].index.values.tolist()\n",
    "    is_oos_index.append([train, test])\n",
    "\n",
    "# ---------------------------------- Train Models\n",
    "OUTPUTS=[] # output will be saved here\n",
    "HYPERS=[] # hyperparameters will be saved here\n",
    "df_summary_OUTPUTS=[]\n",
    "for m in ['RIDGE', 'SVM','KNN','RF','XGBOOST','GBDT', 'ANN','LSTM','GRU']: # 'RIDGE', 'SVM','KNN','RF','XGBOOST','GBDT', 'ANN','LSTM','GRU'\n",
    "    model, param_grid = all_model(m)\n",
    "    # ------- columns\n",
    "    i=i[['time','open','close','high','low','return',\n",
    "         'ema10','ema20','ema50','ema200', 'ema100',\n",
    "         'macd_slow', 'macd_fast',\n",
    "         'rsi',\n",
    "         'sto_main', 'sto_signal',\n",
    "         'bb_mid', 'bb_down', 'bb_up',\n",
    "         'cci','atr','willr', 'ADX_14', 'DMP_14', 'DMN_14',\n",
    "         'momentum','avg_price','range','ohlc']]\n",
    "    i=i.dropna()\n",
    "    df_res_full=pd.DataFrame()\n",
    "    best_list_hyper=[]\n",
    "    # ! - following loop code help to choose exact window of rolling wlak forward approach. All models were trained on 40 windows. \n",
    "    # ! - range(1) mean train models, tuning hyperparameter and prediction process will be run only first one window of rolling walk forward approach.\n",
    "    # ! - range(len(is_oos_index)) mean train models, tuning hyperparameter and prediction process will be run all window(40) of rolling walk forward approach.\n",
    "    for a in range(1): # len(is_oos_index) # Number of windows (rolling walk forward approach)\n",
    "         daily_range=daily_range\n",
    "         print('Model:',m,' ','Window:',a) # It will show - what model works on what window\n",
    "         # ------- train, validation index\n",
    "         train = i.iloc[i.index.isin(is_oos_index[a][0])]\n",
    "         # ------- test index\n",
    "         test = i.iloc[i.index.isin(is_oos_index[a][1])]\n",
    "         train=train.reset_index(drop=True)\n",
    "         test=test.reset_index(drop=True)\n",
    "         dateindex=test[['time']]\n",
    "         # -------  target and features - train, validation\n",
    "         X_train=train[['ema10','ema20','ema50','ema200', 'ema100',\n",
    "                       'macd_slow', 'macd_fast',\n",
    "                       'rsi',\n",
    "                       'sto_main', 'sto_signal',\n",
    "                       'bb_mid', 'bb_down', 'bb_up',\n",
    "                       'cci','atr','willr', 'ADX_14', 'DMP_14', 'DMN_14',\n",
    "                        'momentum','avg_price','range','ohlc']]\n",
    "         y_train = train[['return']]\n",
    "         # ------- target and features - test\n",
    "         X_test_close=test[['open','close']]\n",
    "         X_test=test[['ema10','ema20','ema50','ema200', 'ema100',\n",
    "                       'macd_slow', 'macd_fast',\n",
    "                       'rsi',\n",
    "                       'sto_main', 'sto_signal',\n",
    "                       'bb_mid', 'bb_down', 'bb_up',\n",
    "                       'cci','atr','willr', 'ADX_14', 'DMP_14', 'DMN_14',\n",
    "                       'momentum','avg_price','range','ohlc']]\n",
    "         y_test = test[['return']]\n",
    "         # ------- Scaler\n",
    "         scaler = MinMaxScaler()\n",
    "         X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "         X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "         # ------- train and validation index\n",
    "         train_indices=X_train.iloc[:daily_range].index.values # 3year=train+validation. 600row=train. others=validation \n",
    "         valid_indices=X_train.iloc[daily_range:].index.values\n",
    "         custom_cv = [[train_indices,valid_indices]] # index of train and validation set\n",
    "         df_res_full_add=pd.DataFrame(dateindex,columns=['time'])\n",
    "         df_res_full_add=df_res_full_add.join(X_test_close)\n",
    "         df_res_full_add=df_res_full_add.join(y_test)\n",
    "         scoring_list=['neg_mean_absolute_error','neg_mean_squared_error','neg_mean_absolute_percentage_error','r2'] # MAE, MSE, MAPE, R2\n",
    "         # ------- RandomSearchCV, train, prediction process\n",
    "         model_grid = RandomizedSearchCV(model, \n",
    "                                         param_distributions=param_grid, # hyperparameter\n",
    "                                         n_iter=20, # number of iteration\n",
    "                                         cv=custom_cv, # train, validation\n",
    "                                         return_train_score=True, \n",
    "                                         scoring=scoring_list[0]) # MAE as loss function\n",
    "         model_grid.fit(X_train,y_train) # train model\n",
    "         predict_Model=model_grid.predict(X_test) # prediction using test set\n",
    "         # ------- 1st and 3rd quartile of train sets\n",
    "         quar75=y_train.quantile([0.75]).values # Threshold for signal\n",
    "         quar25=y_train.quantile([0.25]).values # Threshold for signal\n",
    "         predict_Model=pd.DataFrame(predict_Model, columns=['predict_Model'])\n",
    "         df_res_full_add=df_res_full_add.join(predict_Model)\n",
    "         df_res_full_add[\"quar75\"]=float(quar75) # CHOOSE\n",
    "         df_res_full_add[\"quar25\"]=float(quar25) # CHOOSE\n",
    "         # ------- Mean Absolute Error\n",
    "         df_res_full_add['mae_Model']=float(model_grid.cv_results_['mean_test_score'][0]*-1)\n",
    "         df_res_full_add['mae_Model'] = mean_absolute_error(y_test, df_res_full_add['predict_Model'])\n",
    "         # ------- Hyperparameters\n",
    "         best_list_hyper.append(model_grid.best_params_)\n",
    "         best_list_hyper.append(m)\n",
    "         df_res_full_add['signal_Model']=0\n",
    "\n",
    "        # ------- 1. Transforming Rule (ML based) - buy and sell, only buy, only sell\n",
    "        # !- following 4 row code shows types of trading signal. If i consider buy and sell signal, i run 2 row code with \"Buy and Sell\" comment.\n",
    "        # !- following 4 row code shows types of trading signal. If i consider only buy signal, i run 1 row code with Only buy\" comment.\n",
    "        # !- following 4 row code shows types of trading signal. If i consider only sell signal, i run 2 row code with \"Only sell\" comment.\n",
    "        #  df_res_full_add['signal_Model'][(df_res_full_add['predict_Model'] > 0)] = 1 # Only buy\n",
    "        #  df_res_full_add['signal_Model'][(df_res_full_add['predict_Model'] < 0)] = -1 # Only sell\n",
    "         df_res_full_add['signal_Model'][(df_res_full_add['predict_Model'] >= df_res_full_add['quar75'])] = 1 # Buy and Sell\n",
    "         df_res_full_add['signal_Model'][(df_res_full_add['predict_Model'] <= df_res_full_add['quar25'])] = -1 # Buy and Sell\n",
    "         df_res_full=pd.concat([df_res_full,df_res_full_add])\n",
    "\n",
    "    # ---------------------------------- Equity\n",
    "    HYPERS.append(best_list_hyper)\n",
    "    pipvalue=0.1 # pipvalue is 0.1$ per pip. Because lot size is 1 micro lot\n",
    "    df_res_full['close_next']=df_res_full['close'].shift(-1)\n",
    "    df_res_full['open_next']=df_res_full['open'].shift(-1)\n",
    "    df_res_full['changes']=(df_res_full['close_next']-df_res_full['open_next'])*(10**2)*pipvalue\n",
    "    df_res_full['equity_BAH'] = df_res_full['changes'].cumsum()+1000\n",
    "\n",
    "    df_res_full['profit']=0\n",
    "    df_res_full['cost']=0\n",
    "    df_res_full['cost'][df_res_full['signal_Model']!=0]=df_res_full['close']*1000*0.0002 # transaction cost 0.02%\n",
    "    df_res_full['cost'][df_res_full['signal_Model']==df_res_full['signal_Model'].shift(1)]=0\n",
    "    df_res_full['changes_Model']=df_res_full['changes']-df_res_full['cost']\n",
    "\n",
    "    df_res_full['profit'][(df_res_full['signal_Model'] == 1) &\n",
    "                        (df_res_full['changes_Model'] > 0)] = abs(df_res_full['changes_Model'])\n",
    "    df_res_full['profit'][(df_res_full['signal_Model'] == 1) &\n",
    "                        (df_res_full['changes_Model'] < 0)] = abs(df_res_full['changes_Model'])*-1\n",
    "    df_res_full['profit'][(df_res_full['signal_Model'] == -1) &\n",
    "                        (df_res_full['changes_Model'] < 0)] = abs(df_res_full['changes_Model'])\n",
    "    df_res_full['profit'][(df_res_full['signal_Model'] == -1) &\n",
    "                        (df_res_full['changes_Model'] > 0)] = abs(df_res_full['changes_Model'])*-1\n",
    "    df_res_full['profit'][df_res_full['signal_Model']==0]=0\n",
    "    df_res_full['equity_Model'] = df_res_full['profit'].cumsum()+1000 # Initial capital 1000 USD\n",
    "    # ---------------------------------- Performance table\n",
    "    df_summary=pd.DataFrame([df_res_full['time'].iloc[0],\n",
    "                             df_res_full['time'].iloc[-1],\n",
    "                         1000, # Start\n",
    "                         df_res_full['equity_Model'].iloc[-1],  # End\n",
    "                         df_res_full['profit'][df_res_full['profit']>0].sum(), # Gross profit\n",
    "                         df_res_full['profit'][df_res_full['profit']<0].sum(), # Gross loss\n",
    "                         df_res_full['profit'][df_res_full['profit']>0].sum()+df_res_full['profit'][df_res_full['profit']<0].sum(), # Net profit\n",
    "                         '{:.1%}'.format((df_res_full['profit'][df_res_full['profit']>0].sum()+df_res_full['profit'][df_res_full['profit']<0].sum())/1000), # Return on initial capital\n",
    "                         df_res_full['profit'][df_res_full['profit']>0].sum()/df_res_full['profit'][df_res_full['profit']<0].sum(), # Profit factor\n",
    "                         df_res_full['cost'][df_res_full['cost']!=0].count(), # Total number of trades\n",
    "                         '{:.1%}'.format((df_res_full['cost'][(df_res_full['cost']!=0) & (df_res_full['signal_Model']==-1)].count())/(df_res_full['cost'][df_res_full['cost']!=0].count())), # % sell\n",
    "                         '{:.1%}'.format((df_res_full['cost'][(df_res_full['cost']!=0) & (df_res_full['signal_Model']==1)].count())/(df_res_full['cost'][df_res_full['cost']!=0].count())), # % buy\n",
    "                         df_res_full['cost'][(df_res_full['cost']!=0) & (df_res_full['profit']>0)].count(), # winning trades\n",
    "                         df_res_full['cost'][(df_res_full['cost']!=0) & (df_res_full['profit']<0)].count(), # Lossing trades\n",
    "                         '{:.1%}'.format((df_res_full['cost'][(df_res_full['cost']!=0) & (df_res_full['profit']>0)].count())/df_res_full['cost'][df_res_full['cost']!=0].count()), #%profitable\n",
    "                         (df_res_full['profit'][df_res_full['profit']>0].sum()+df_res_full['profit'][df_res_full['profit']<0].sum())/(df_res_full['cost'][df_res_full['cost']!=0].count()), # Total number of trades\n",
    "                         (df_res_full['profit'][df_res_full['profit']>0].sum())/(df_res_full['cost'][(df_res_full['cost']!=0) & (df_res_full['profit']>0)].count()), # Avg.winning trade\n",
    "                         (df_res_full['profit'][df_res_full['profit']<0].sum())/(df_res_full['cost'][(df_res_full['cost']!=0) & (df_res_full['profit']<0)].count()), # Avg.lossing trade\n",
    "                         ((df_res_full['profit'][df_res_full['profit']>0].sum())/(df_res_full['cost'][(df_res_full['cost']!=0) & (df_res_full['profit']>0)].count()))/((df_res_full['profit'][df_res_full['profit']<0].sum())/(df_res_full['cost'][(df_res_full['cost']!=0) & (df_res_full['profit']<0)].count())), # Ratio\n",
    "                         df_res_full['profit'].max(), # Largest winning trade\n",
    "                         df_res_full['profit'].min(), # Largest lossing trade\n",
    "                         df_res_full['cost'].sum(),\n",
    "                         calculate_max_drawdown((df_res_full['equity_Model']-df_res_full['equity_Model'].shift(1))/df_res_full['equity_Model'].shift(1)),\n",
    "                         calculate_sharpe_ratio((df_res_full['equity_Model']-df_res_full['equity_Model'].shift(1))/df_res_full['equity_Model'].shift(1),0),\n",
    "                         calculate_roi(df_res_full['equity_Model']),\n",
    "                         df_res_full['mae_Model'].mean()\n",
    "                         ],\n",
    "                        columns=[str(m)],\n",
    "                        index=['start_date','end_date','Start','End','Gross profit','Gross loss','Total Net profit', 'Return on initial capital',\n",
    "                               'Profit factor','Total number of trades',\n",
    "                               '%sell','%buy','Winning trades','Lossing trades','%profitable','Avg.Trade Net profit',\n",
    "                               'Avg.Winning trade','Avg.Lossing trade','Ratio Avg.Win:Avg.Loss','Largest Winning trade','Largest Lossing trade','Cost',\n",
    "                               'MD', 'IR/SR','ROI','MAE'])\n",
    "    df_summary_OUTPUTS.append(df_summary)\n",
    "    df_res_full=df_res_full.rename(columns = {'equity_Model':str(m)})\n",
    "    OUTPUTS.append(df_res_full[['time','equity_BAH',str(m)]])\n",
    "\n",
    "df_outputs=pd.concat([OUTPUTS[0]['time'].reset_index(), # combine performance tables of all ML models\n",
    "    OUTPUTS[0]['equity_BAH'].reset_index(),\n",
    "    OUTPUTS[0]['RIDGE'].reset_index(),\n",
    "                     OUTPUTS[1]['SVM'].reset_index(),\n",
    "                     OUTPUTS[2]['KNN'].reset_index(),\n",
    "                     OUTPUTS[3]['RF'].reset_index(),\n",
    "                     OUTPUTS[4]['XGBOOST'].reset_index(),\n",
    "                     OUTPUTS[5]['GBDT'].reset_index(),\n",
    "                     OUTPUTS[6]['ANN'].reset_index(),\n",
    "                     OUTPUTS[7]['LSTM'].reset_index(),\n",
    "                     OUTPUTS[8]['GRU'].reset_index()],axis=1) # 'RIDGE', 'SVM','KNN','RF','XGBOOST','GBDT', 'ANN','LSTM','GRU'\n",
    "\n",
    "df_outputs = df_outputs.T.drop_duplicates().T\n",
    "df_summary_OUTPUTS = pd.concat(df_summary_OUTPUTS,axis=1)\n",
    "print(df_summary_OUTPUTS)\n",
    "\n",
    "# ---------------------------------- Traditional MA cross strategy\n",
    "check=pd.DataFrame(columns=['short','long', 'SRs','iter'])\n",
    "for a in range(len(is_oos_index)): # len(is_oos_index)\n",
    "         train = i.iloc[i.index.isin(is_oos_index[a][0])]\n",
    "         test = i.iloc[i.index.isin(is_oos_index[a][1])]\n",
    "         train=train.reset_index(drop=True)\n",
    "         test=test.reset_index(drop=True)\n",
    "         both=pd.concat([train])\n",
    "         SR_list=[]\n",
    "         best_com=pd.DataFrame(columns=['short','long', 'SRs'])\n",
    "         # ---------- MAs combinations\n",
    "         for short, long in zip(['ema10','ema10','ema10','ema10',\n",
    "                        'ema20','ema20','ema20',\n",
    "                        'ema50','ema50',\n",
    "                        'ema100'],\n",
    "                         ['ema20','ema50','ema100','ema200',\n",
    "                          'ema50','ema100','ema200',\n",
    "                          'ema100','ema200',\n",
    "                          'ema200']):\n",
    "             name_in=str(short+long)\n",
    "             MA_cross = both[['time','open','close',short,long]]\n",
    "             MA_cross['signal_Model']=0\n",
    "             # ------------- 2. Transforming Rule - buy and sell, only buy, only sell\n",
    "             # !- following 2 row code shows types of trading signal. If i consider buy and sell signal, i run both 2 row code with 'only buy' or 'only sell'.\n",
    "             # !- following 2 row code shows types of trading signal. If i consider only buy signal, i run 1 row code with only buy\" comment.\n",
    "             # !- following 2 row code shows types of trading signal. If i consider only sell signal, i run 2 row code with \"only sell\" comment.\n",
    "             MA_cross['signal_Model'][MA_cross[long]<MA_cross[short]]=1 # only buy\n",
    "             MA_cross['signal_Model'][MA_cross[long]>MA_cross[short]]=-1 # only sell\n",
    "             pipvalue=0.1 # based on lot size\n",
    "             MA_cross['close_next']=MA_cross['close'].shift(-1)\n",
    "             MA_cross['open_next']=MA_cross['open'].shift(-1)\n",
    "             MA_cross['changes']=(MA_cross['close_next']-MA_cross['open_next'])*(10**2)*pipvalue\n",
    "             MA_cross['profit']=0\n",
    "             MA_cross['cost']=0\n",
    "             # MA_cross['cost'][MA_cross['signal_Model']!=0]=cost*pipvalue\n",
    "             MA_cross['cost'][MA_cross['signal_Model']!=0]=MA_cross['close']*1000*0.0002\n",
    "             MA_cross['cost'][MA_cross['signal_Model']==MA_cross['signal_Model'].shift(1)]=0\n",
    "             MA_cross['changes_Model']=MA_cross['changes']-MA_cross['cost']\n",
    "\n",
    "             MA_cross['profit'][(MA_cross['signal_Model'] == 1) &\n",
    "                                 (MA_cross['changes_Model'] > 0)] = abs(MA_cross['changes_Model'])\n",
    "             MA_cross['profit'][(MA_cross['signal_Model'] == 1) &\n",
    "                                 (MA_cross['changes_Model'] < 0)] = abs(MA_cross['changes_Model'])*-1\n",
    "             MA_cross['profit'][(MA_cross['signal_Model'] == -1) &\n",
    "                                 (MA_cross['changes_Model'] < 0)] = abs(MA_cross['changes_Model'])\n",
    "             MA_cross['profit'][(MA_cross['signal_Model'] == -1) &\n",
    "                                 (MA_cross['changes_Model'] > 0)] = abs(MA_cross['changes_Model'])*-1\n",
    "             MA_cross['profit'][MA_cross['signal_Model']==0]=0\n",
    "             MA_cross['equity_Model'] = MA_cross['profit'].cumsum()+1000\n",
    "             SR=calculate_sharpe_ratio((MA_cross['equity_Model']-MA_cross['equity_Model'].shift(1))/MA_cross['equity_Model'].shift(1),0)\n",
    "             SR_list.append(SR)\n",
    "             best_com=best_com._append({'short': short,'long': long, 'SRs': SR,'iter':a}, ignore_index=True)\n",
    "         # ----------- Best combination of MA\n",
    "         x=best_com[best_com.SRs==max(best_com.SRs)]\n",
    "         check=check._append(x)\n",
    "\n",
    "# ----------- Equity using best MA combination\n",
    "MA_res=pd.DataFrame(columns=['time', 'open', 'close', 'short', 'long', 'chosen','signal_Model'])\n",
    "for a in range(1): # len(is_oos_index)\n",
    "         i=i[i.time>='2003-01-01']\n",
    "         i=i[i.time<='2023-06-30']\n",
    "         train = i.iloc[i.index.isin(is_oos_index[a][0])]\n",
    "         test = i.iloc[i.index.isin(is_oos_index[a][1])]\n",
    "         train=train.reset_index(drop=True)\n",
    "         test=test.reset_index(drop=True)\n",
    "         MA_cross = test[['time','open','close',check.iloc[a]['short'],check.iloc[a]['long']]]\n",
    "         #  print(MA_cross.columns)\n",
    "         MA_cross.columns.values[-2] = \"short\"\n",
    "         MA_cross.columns.values[-1] = \"long\"\n",
    "         MA_cross['signal_Model']=0\n",
    "         # ------------- 3. Transforming Rule - buy and sell, only buy, only sell\n",
    "         # !- following 2 row code shows types of trading signal. If i consider buy and sell signal, i run both 2 row code with 'only buy' or 'only sell'.\n",
    "         # !- following 2 row code shows types of trading signal. If i consider only buy signal, i run 1 row code with only buy\" comment.\n",
    "         # !- following 2 row code shows types of trading signal. If i consider only sell signal, i run 2 row code with \"only sell\" comment.\n",
    "         MA_cross['signal_Model'][MA_cross['long']<MA_cross[\"short\"]]=1 # only buy\n",
    "         MA_cross['signal_Model'][MA_cross[\"long\"]>MA_cross[\"short\"]]=-1 # only sell\n",
    "         MA_cross['chosen']=check.iloc[a]['short']+check.iloc[a]['long']\n",
    "         MA_res=pd.concat([MA_res,MA_cross])\n",
    "\n",
    "pipvalue=0.1 # based on lot size\n",
    "MA_res['close_next']=MA_res['close'].shift(-1)\n",
    "MA_res['open_next']=MA_res['open'].shift(-1)\n",
    "MA_res['changes']=(MA_res['close_next']-MA_res['open_next'])*(10**2)*pipvalue\n",
    "MA_res['profit']=0\n",
    "MA_res['cost']=0\n",
    "# MA_res['cost'][MA_res['signal_Model']!=0]=cost*pipvalue\n",
    "MA_res['cost'][MA_res['signal_Model']!=0]=MA_res['close']*1000*0.0002\n",
    "MA_res['cost'][MA_res['signal_Model']==MA_res['signal_Model'].shift(1)]=0\n",
    "MA_res['changes_Model']=MA_res['changes']-MA_res['cost']\n",
    "MA_res['profit'][(MA_res['signal_Model'] == 1) &\n",
    "                    (MA_res['changes_Model'] > 0)] = abs(MA_res['changes_Model'])\n",
    "MA_res['profit'][(MA_res['signal_Model'] == 1) &\n",
    "                    (MA_res['changes_Model'] < 0)] = abs(MA_res['changes_Model'])*-1\n",
    "MA_res['profit'][(MA_res['signal_Model'] == -1) &\n",
    "                    (MA_res['changes_Model'] < 0)] = abs(MA_res['changes_Model'])\n",
    "MA_res['profit'][(MA_res['signal_Model'] == -1) &\n",
    "                    (MA_res['changes_Model'] > 0)] = abs(MA_res['changes_Model'])*-1\n",
    "MA_res['profit'][MA_res['signal_Model']==0]=0\n",
    "MA_res['equity_Model'] = MA_res['profit'].cumsum()+1000\n",
    "# ---------------------------------- Performance table\n",
    "df_summary_MAs=pd.DataFrame([MA_res['time'].iloc[0],\n",
    "                        MA_res['time'].iloc[-1],\n",
    "                    1000, # Start\n",
    "                    MA_res['equity_Model'].iloc[-1],  # End\n",
    "                    MA_res['profit'][MA_res['profit']>0].sum(), # Gross profit\n",
    "                    MA_res['profit'][MA_res['profit']<0].sum(), # Gross loss\n",
    "                    MA_res['profit'][MA_res['profit']>0].sum()+MA_res['profit'][MA_res['profit']<0].sum(), # Net profit\n",
    "                    '{:.1%}'.format((MA_res['profit'][MA_res['profit']>0].sum()+MA_res['profit'][MA_res['profit']<0].sum())/1000), # Return on initial capital\n",
    "                    MA_res['profit'][MA_res['profit']>0].sum()/MA_res['profit'][MA_res['profit']<0].sum(), # Profit factor\n",
    "                    MA_res['cost'][MA_res['cost']!=0].count(), # Total number of trades\n",
    "                    '{:.1%}'.format((MA_res['cost'][(MA_res['cost']!=0) & (MA_res['signal_Model']==-1)].count())/(MA_res['cost'][MA_res['cost']!=0].count())), # % sell\n",
    "                    '{:.1%}'.format((MA_res['cost'][(MA_res['cost']!=0) & (MA_res['signal_Model']==1)].count())/(MA_res['cost'][MA_res['cost']!=0].count())), # % buy\n",
    "                    MA_res['cost'][(MA_res['cost']!=0) & (MA_res['profit']>0)].count(), # winning trades\n",
    "                    MA_res['cost'][(MA_res['cost']!=0) & (MA_res['profit']<0)].count(), # Lossing trades\n",
    "                    '{:.1%}'.format((MA_res['cost'][(MA_res['cost']!=0) & (MA_res['profit']>0)].count())/MA_res['cost'][MA_res['cost']!=0].count()), #%profitable\n",
    "                    (MA_res['profit'][MA_res['profit']>0].sum()+MA_res['profit'][MA_res['profit']<0].sum())/(MA_res['cost'][MA_res['cost']!=0].count()), # Total number of trades\n",
    "                    (MA_res['profit'][MA_res['profit']>0].sum())/(MA_res['cost'][(MA_res['cost']!=0) & (MA_res['profit']>0)].count()), # Avg.winning trade\n",
    "                    (MA_res['profit'][MA_res['profit']<0].sum())/(MA_res['cost'][(MA_res['cost']!=0) & (MA_res['profit']<0)].count()), # Avg.lossing trade\n",
    "                    ((MA_res['profit'][MA_res['profit']>0].sum())/(MA_res['cost'][(MA_res['cost']!=0) & (MA_res['profit']>0)].count()))/((MA_res['profit'][MA_res['profit']<0].sum())/(MA_res['cost'][(MA_res['cost']!=0) & (MA_res['profit']<0)].count())), # Ratio\n",
    "                    MA_res['profit'].max(), # Largest winning trade\n",
    "                    MA_res['profit'].min(), # Largest lossing trade\n",
    "                    MA_res['cost'].sum(),\n",
    "                    calculate_max_drawdown((MA_res['equity_Model']-MA_res['equity_Model'].shift(1))/MA_res['equity_Model'].shift(1)),\n",
    "                    calculate_sharpe_ratio((MA_res['equity_Model']-MA_res['equity_Model'].shift(1))/MA_res['equity_Model'].shift(1),0),\n",
    "                    calculate_roi(MA_res['equity_Model'])\n",
    "                    ],\n",
    "                    columns=[str('MAs')],\n",
    "                    index=['start_date','end_date','Start','End','Gross profit','Gross loss','Total Net profit', 'Return on initial capital',\n",
    "                          'Profit factor','Total number of trades',\n",
    "                          '%sell','%buy','Winning trades','Lossing trades','%profitable','Avg.Trade Net profit',\n",
    "                          'Avg.Winning trade','Avg.Lossing trade','Ratio Avg.Win:Avg.Loss','Largest Winning trade','Largest Lossing trade','Cost',\n",
    "                          'MD', 'IR/SR','ROI'])\n",
    "df_summary_MAs\n",
    "# ---------------------------------- Benchmark Strategy\n",
    "i=i[i.time>=MA_res['time'].iloc[0]]\n",
    "i=i[i.time<=MA_res['time'].iloc[-1]]\n",
    "benchmark = i[['time','open','close']]\n",
    "benchmark['signal_Model']=0\n",
    "benchmark['signal_Model']=1\n",
    "benchmark['signal_Model'].iloc[-1]=-1\n",
    "pipvalue=0.1 # based on lot size\n",
    "benchmark['close_next']=benchmark['close'].shift(-1)\n",
    "benchmark['open_next']=benchmark['open'].shift(-1)\n",
    "benchmark['changes']=(benchmark['close_next']-benchmark['open_next'])*(10**2)*pipvalue\n",
    "benchmark['profit']=0\n",
    "benchmark['cost']=0\n",
    "benchmark['cost'][benchmark['signal_Model']!=0]=benchmark['close']*1000*0.0002\n",
    "benchmark['cost'][benchmark['signal_Model']==benchmark['signal_Model'].shift(1)]=0\n",
    "benchmark['changes_Model']=benchmark['changes']-benchmark['cost']\n",
    "benchmark['profit'][(benchmark['signal_Model'] == 1) &\n",
    "                    (benchmark['changes_Model'] > 0)] = abs(benchmark['changes_Model'])\n",
    "benchmark['profit'][(benchmark['signal_Model'] == 1) &\n",
    "                    (benchmark['changes_Model'] < 0)] = abs(benchmark['changes_Model'])*-1\n",
    "benchmark['profit'][(benchmark['signal_Model'] == -1) &\n",
    "                    (benchmark['changes_Model'] < 0)] = abs(benchmark['changes_Model'])\n",
    "benchmark['profit'][(benchmark['signal_Model'] == -1) &\n",
    "                    (benchmark['changes_Model'] > 0)] = abs(benchmark['changes_Model'])*-1\n",
    "benchmark['profit'][benchmark['signal_Model']==0]=0\n",
    "benchmark['equity_Model'] = benchmark['profit'].cumsum()+1000\n",
    "# ---------------------------------- Performance table\n",
    "df_summary_benchmark=pd.DataFrame([benchmark['time'].iloc[0],\n",
    "                        benchmark['time'].iloc[-1],\n",
    "                    1000, # Start\n",
    "                    benchmark['equity_Model'].iloc[-1],  # End\n",
    "                    benchmark['profit'][benchmark['profit']>0].sum(), # Gross profit\n",
    "                    benchmark['profit'][benchmark['profit']<0].sum(), # Gross loss\n",
    "                    benchmark['profit'][benchmark['profit']>0].sum()+benchmark['profit'][benchmark['profit']<0].sum(), # Net profit\n",
    "                    '{:.1%}'.format((benchmark['profit'][benchmark['profit']>0].sum()+benchmark['profit'][benchmark['profit']<0].sum())/1000), # Return on initial capital\n",
    "                    benchmark['profit'][benchmark['profit']>0].sum()/benchmark['profit'][benchmark['profit']<0].sum(), # Profit factor\n",
    "                    benchmark['cost'][benchmark['cost']!=0].count(), # Total number of trades\n",
    "                    '{:.1%}'.format((benchmark['cost'][(benchmark['cost']!=0) & (benchmark['signal_Model']==-1)].count())/(benchmark['cost'][benchmark['cost']!=0].count())), # % sell\n",
    "                    '{:.1%}'.format((benchmark['cost'][(benchmark['cost']!=0) & (benchmark['signal_Model']==1)].count())/(benchmark['cost'][benchmark['cost']!=0].count())), # % buy\n",
    "                    benchmark['cost'][(benchmark['cost']!=0) & (benchmark['profit']>0)].count(), # winning trades\n",
    "                    benchmark['cost'][(benchmark['cost']!=0) & (benchmark['profit']<0)].count(), # Lossing trades\n",
    "                    '{:.1%}'.format((benchmark['cost'][(benchmark['cost']!=0) & (benchmark['profit']>0)].count())/benchmark['cost'][benchmark['cost']!=0].count()), #%profitable\n",
    "                    (benchmark['profit'][benchmark['profit']>0].sum()+benchmark['profit'][benchmark['profit']<0].sum())/(benchmark['cost'][benchmark['cost']!=0].count()), # Total number of trades\n",
    "                    (benchmark['profit'][benchmark['profit']>0].sum())/(benchmark['cost'][(benchmark['cost']!=0) & (benchmark['profit']>0)].count()), # Avg.winning trade\n",
    "                    (benchmark['profit'][benchmark['profit']<0].sum())/(benchmark['cost'][(benchmark['cost']!=0) & (benchmark['profit']<0)].count()), # Avg.lossing trade\n",
    "                    ((benchmark['profit'][benchmark['profit']>0].sum())/(benchmark['cost'][(benchmark['cost']!=0) & (benchmark['profit']>0)].count()))/((benchmark['profit'][benchmark['profit']<0].sum())/(benchmark['cost'][(benchmark['cost']!=0) & (benchmark['profit']<0)].count())), # Ratio\n",
    "                    benchmark['profit'].max(), # Largest winning trade\n",
    "                    benchmark['profit'].min(), # Largest lossing trade\n",
    "                    benchmark['cost'].sum(),\n",
    "                    calculate_max_drawdown((benchmark['equity_Model']-benchmark['equity_Model'].shift(1))/benchmark['equity_Model'].shift(1)),\n",
    "                    calculate_sharpe_ratio((benchmark['equity_Model']-benchmark['equity_Model'].shift(1))/benchmark['equity_Model'].shift(1),0),\n",
    "                    calculate_roi(benchmark['equity_Model'])\n",
    "                    ],\n",
    "                    columns=['benchmark'],\n",
    "                    index=['start_date','end_date','Start','End','Gross profit','Gross loss','Total Net profit', 'Return on initial capital',\n",
    "                          'Profit factor','Total number of trades',\n",
    "                          '%sell','%buy','Winning trades','Lossing trades','%profitable','Avg.Trade Net profit',\n",
    "                          'Avg.Winning trade','Avg.Lossing trade','Ratio Avg.Win:Avg.Loss','Largest Winning trade','Largest Lossing trade','Cost',\n",
    "                          'MD', 'IR/SR','ROI'])\n",
    "df_summary_benchmark\n",
    "\n",
    "table=pd.concat([df_summary_OUTPUTS,df_summary_MAs,df_summary_benchmark],axis=1)\n",
    "MA_res.columns = [*MA_res.columns[:-1], 'equity_MA']\n",
    "benchmark.columns = [*benchmark.columns[:-1], 'equity_benchmark']\n",
    "equity=pd.concat([df_outputs,MA_res[['time','equity_MA']].reset_index(),benchmark[['time','equity_benchmark']].reset_index()],axis=1)\n",
    "hyper=HYPERS\n",
    "equity = equity.drop('equity_BAH', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02645283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-31T18:35:28.611986Z",
     "iopub.status.busy": "2023-12-31T18:35:28.611606Z",
     "iopub.status.idle": "2023-12-31T18:35:49.279889Z",
     "shell.execute_reply": "2023-12-31T18:35:49.279035Z"
    },
    "id": "lk4qCOdAcRGL",
    "papermill": {
     "duration": 20.715843,
     "end_time": "2023-12-31T18:35:49.282511",
     "exception": false,
     "start_time": "2023-12-31T18:35:28.566668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>time</th>\n",
       "      <th>RIDGE</th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RF</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>GBDT</th>\n",
       "      <th>ANN</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "      <th>index</th>\n",
       "      <th>time</th>\n",
       "      <th>equity_MA</th>\n",
       "      <th>index</th>\n",
       "      <th>time</th>\n",
       "      <th>equity_benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>2003-06-24 00:00:00</td>\n",
       "      <td>998.61848</td>\n",
       "      <td>1000</td>\n",
       "      <td>999.99852</td>\n",
       "      <td>998.01028</td>\n",
       "      <td>998.5469</td>\n",
       "      <td>997.98696</td>\n",
       "      <td>1000.9104</td>\n",
       "      <td>999.75722</td>\n",
       "      <td>998.8653</td>\n",
       "      <td>124</td>\n",
       "      <td>2003-06-24</td>\n",
       "      <td>1000.9104</td>\n",
       "      <td>906</td>\n",
       "      <td>2003-06-24</td>\n",
       "      <td>1000.9104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>2003-06-25 00:00:00</td>\n",
       "      <td>998.61848</td>\n",
       "      <td>1000</td>\n",
       "      <td>999.99852</td>\n",
       "      <td>998.01028</td>\n",
       "      <td>998.5469</td>\n",
       "      <td>997.98696</td>\n",
       "      <td>1000.7944</td>\n",
       "      <td>999.64122</td>\n",
       "      <td>998.8653</td>\n",
       "      <td>125</td>\n",
       "      <td>2003-06-25</td>\n",
       "      <td>1000.7944</td>\n",
       "      <td>907</td>\n",
       "      <td>2003-06-25</td>\n",
       "      <td>1000.7944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>2003-06-26 00:00:00</td>\n",
       "      <td>998.84084</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000.22088</td>\n",
       "      <td>998.23264</td>\n",
       "      <td>998.76926</td>\n",
       "      <td>998.20932</td>\n",
       "      <td>1000.8004</td>\n",
       "      <td>999.64722</td>\n",
       "      <td>998.8653</td>\n",
       "      <td>126</td>\n",
       "      <td>2003-06-26</td>\n",
       "      <td>1000.8004</td>\n",
       "      <td>908</td>\n",
       "      <td>2003-06-26</td>\n",
       "      <td>1000.8004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>2003-06-27 00:00:00</td>\n",
       "      <td>998.84084</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000.22088</td>\n",
       "      <td>998.23264</td>\n",
       "      <td>998.76926</td>\n",
       "      <td>998.20932</td>\n",
       "      <td>1000.8944</td>\n",
       "      <td>999.74122</td>\n",
       "      <td>998.8653</td>\n",
       "      <td>127</td>\n",
       "      <td>2003-06-27</td>\n",
       "      <td>1000.8944</td>\n",
       "      <td>909</td>\n",
       "      <td>2003-06-27</td>\n",
       "      <td>1000.8944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>2003-06-30 00:00:00</td>\n",
       "      <td>998.84084</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000.22088</td>\n",
       "      <td>998.23264</td>\n",
       "      <td>998.76926</td>\n",
       "      <td>998.20932</td>\n",
       "      <td>1000.8944</td>\n",
       "      <td>999.74122</td>\n",
       "      <td>998.8653</td>\n",
       "      <td>128</td>\n",
       "      <td>2003-06-30</td>\n",
       "      <td>1000.8944</td>\n",
       "      <td>910</td>\n",
       "      <td>2003-06-30</td>\n",
       "      <td>1000.8944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                 time      RIDGE   SVM         KNN         RF  \\\n",
       "124    124  2003-06-24 00:00:00  998.61848  1000   999.99852  998.01028   \n",
       "125    125  2003-06-25 00:00:00  998.61848  1000   999.99852  998.01028   \n",
       "126    126  2003-06-26 00:00:00  998.84084  1000  1000.22088  998.23264   \n",
       "127    127  2003-06-27 00:00:00  998.84084  1000  1000.22088  998.23264   \n",
       "128    128  2003-06-30 00:00:00  998.84084  1000  1000.22088  998.23264   \n",
       "\n",
       "       XGBOOST       GBDT        ANN       LSTM       GRU  index       time  \\\n",
       "124   998.5469  997.98696  1000.9104  999.75722  998.8653    124 2003-06-24   \n",
       "125   998.5469  997.98696  1000.7944  999.64122  998.8653    125 2003-06-25   \n",
       "126  998.76926  998.20932  1000.8004  999.64722  998.8653    126 2003-06-26   \n",
       "127  998.76926  998.20932  1000.8944  999.74122  998.8653    127 2003-06-27   \n",
       "128  998.76926  998.20932  1000.8944  999.74122  998.8653    128 2003-06-30   \n",
       "\n",
       "     equity_MA  index       time  equity_benchmark  \n",
       "124  1000.9104    906 2003-06-24         1000.9104  \n",
       "125  1000.7944    907 2003-06-25         1000.7944  \n",
       "126  1000.8004    908 2003-06-26         1000.8004  \n",
       "127  1000.8944    909 2003-06-27         1000.8944  \n",
       "128  1000.8944    910 2003-06-30         1000.8944  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[{'alpha': 0.4645950086618443}, 'RIDGE'],\n",
       " [{'C': 4.177274744134858,\n",
       "   'degree': 1,\n",
       "   'gamma': 8.013003550871234,\n",
       "   'kernel': 'rbf'},\n",
       "  'SVM'],\n",
       " [{'n_neighbors': 5, 'p': 1}, 'KNN'],\n",
       " [{'max_depth': 5,\n",
       "   'max_features': 20,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 35},\n",
       "  'RF'],\n",
       " [{'gamma': 0.0014713530356283435,\n",
       "   'learning_rate': 0.04067333475755425,\n",
       "   'max_depth': 13,\n",
       "   'n_estimators': 178},\n",
       "  'XGBOOST'],\n",
       " [{'learning_rate': 0.022299269025249195, 'max_depth': 3, 'n_estimators': 166},\n",
       "  'GBDT'],\n",
       " [{'batch_size': 64,\n",
       "   'epochs': 30,\n",
       "   'model__hidden_layers': 2,\n",
       "   'model__neurons': 5,\n",
       "   'optimizer': 'rmsprop',\n",
       "   'optimizer__learning_rate': 0.001517362064993024,\n",
       "   'optimizer__momentum': 0.40711547470812437},\n",
       "  'ANN'],\n",
       " [{'batch_size': 128,\n",
       "   'epochs': 20,\n",
       "   'model__hidden_layers': 1,\n",
       "   'model__neurons': 36,\n",
       "   'optimizer': 'rmsprop',\n",
       "   'optimizer__learning_rate': 0.0028770640432852867,\n",
       "   'optimizer__momentum': 0.36632002804261954},\n",
       "  'LSTM'],\n",
       " [{'batch_size': 128,\n",
       "   'epochs': 20,\n",
       "   'model__hidden_layers': 1,\n",
       "   'model__neurons': 20,\n",
       "   'optimizer': 'sgd',\n",
       "   'optimizer__learning_rate': 0.009051160463184499,\n",
       "   'optimizer__momentum': 0.19653151451602213},\n",
       "  'GRU']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RIDGE</th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RF</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>GBDT</th>\n",
       "      <th>ANN</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "      <th>MAs</th>\n",
       "      <th>benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cost</th>\n",
       "      <td>11.56176</td>\n",
       "      <td>0</td>\n",
       "      <td>2.90208</td>\n",
       "      <td>11.80576</td>\n",
       "      <td>10.91514</td>\n",
       "      <td>11.82444</td>\n",
       "      <td>0.2096</td>\n",
       "      <td>2.4379</td>\n",
       "      <td>4.64494</td>\n",
       "      <td>0.2096</td>\n",
       "      <td>0.44008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MD</th>\n",
       "      <td>-0.002122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>-0.00273</td>\n",
       "      <td>-0.002326</td>\n",
       "      <td>-0.002886</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>-0.000931</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>-0.000549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IR/SR</th>\n",
       "      <td>-0.062725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02235</td>\n",
       "      <td>-0.094001</td>\n",
       "      <td>-0.069352</td>\n",
       "      <td>-0.095211</td>\n",
       "      <td>0.129404</td>\n",
       "      <td>-0.022817</td>\n",
       "      <td>-0.115597</td>\n",
       "      <td>0.129404</td>\n",
       "      <td>0.129404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROI</th>\n",
       "      <td>-0.001159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>-0.001231</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.001217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.035016</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.007104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RIDGE       SVM       KNN        RF   XGBOOST      GBDT       ANN  \\\n",
       "Cost   11.56176         0   2.90208  11.80576  10.91514  11.82444    0.2096   \n",
       "MD    -0.002122       0.0 -0.000959  -0.00273 -0.002326 -0.002886 -0.000549   \n",
       "IR/SR -0.062725       NaN   0.02235 -0.094001 -0.069352 -0.095211  0.129404   \n",
       "ROI   -0.001159       0.0  0.000221 -0.001767 -0.001231 -0.001791  0.001217   \n",
       "MAE    0.001191  0.005229  0.003894  0.001292  0.001164  0.001092  0.035016   \n",
       "\n",
       "           LSTM       GRU       MAs benchmark  \n",
       "Cost     2.4379   4.64494    0.2096   0.44008  \n",
       "MD    -0.000931 -0.001403 -0.000549 -0.000549  \n",
       "IR/SR -0.022817 -0.115597  0.129404  0.129404  \n",
       "ROI   -0.000259 -0.001457  0.001217  0.001217  \n",
       "MAE    0.008362  0.007104       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# equity.to_excel('equity.xlsx',index=False) # /kaggle/working/\n",
    "# hyper = pd.DataFrame({'col':hyper})\n",
    "# hyper.to_excel('hyper.xlsx',index=False)\n",
    "# table.to_excel('table.xlsx',index=False)\n",
    "display(equity.tail(5))\n",
    "display(hyper)\n",
    "display(table.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22573f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/H4/7. NZDUSD\n",
      "0.71\n",
      "0.29\n",
      "0.51\n",
      "0.49\n",
      "0.47\n",
      "0.53\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------- Independent t test (Example)\n",
    "i='/H4/7. NZDUSD' #H4/Daily\n",
    "\n",
    "df1 = pd.read_excel('real_output/Outputs'+i+'/Log/buy and sell/equity.xlsx')\n",
    "df2 = pd.read_excel('real_output/Outputs'+i+'/Log/only buy/equity.xlsx')\n",
    "df3 = pd.read_excel('real_output/Outputs'+i+'/Log/only sell/equity.xlsx')\n",
    "df4 = pd.read_excel('real_output/Outputs'+i+'/Simple/buy and sell/equity.xlsx')\n",
    "df5 = pd.read_excel('real_output/Outputs'+i+'/Simple/only buy/equity.xlsx')\n",
    "df6 = pd.read_excel('real_output/Outputs'+i+'/Simple/only sell/equity.xlsx')\n",
    "z1=[]\n",
    "for z in [df1, df2, df3,df4,df5,df6]:\n",
    "  from scipy import stats\n",
    "  RIDGE=z['RIDGE'].pct_change()\n",
    "  KNN=z['KNN'].pct_change()\n",
    "  RF=z['RF'].pct_change()\n",
    "  XGBOOST=z['XGBOOST'].pct_change()\n",
    "  GBDT=z['GBDT'].pct_change()\n",
    "  ANN=z['ANN'].pct_change()\n",
    "  LSTM=z['LSTM'].pct_change()\n",
    "  GRU=z['GRU'].pct_change()\n",
    "  TF=z['equity_MA'].pct_change()\n",
    "  B=z['equity_benchmark'].pct_change()\n",
    "  MLavgz=(RIDGE+KNN+RF+XGBOOST+GBDT+ANN+LSTM+GRU)/8\n",
    "  ML1=(ANN+LSTM+GRU)/3\n",
    "  ML2=(RIDGE+KNN+RF+XGBOOST+GBDT)/5\n",
    "  z1.append(MLavgz)\n",
    "print(i)\n",
    "print(round(stats.ttest_ind(z1[0].dropna(), z1[3].dropna(),alternative='greater').pvalue,2))\n",
    "print(round(stats.ttest_ind(z1[3].dropna(), z1[0].dropna(),alternative='greater').pvalue,2))\n",
    "print(round(stats.ttest_ind(z1[1].dropna(), z1[4].dropna(),alternative='greater').pvalue,2))\n",
    "print(round(stats.ttest_ind(z1[4].dropna(), z1[1].dropna(),alternative='greater').pvalue,2))\n",
    "print(round(stats.ttest_ind(z1[2].dropna(), z1[5].dropna(),alternative='greater').pvalue,2))\n",
    "print(round(stats.ttest_ind(z1[5].dropna(), z1[2].dropna(),alternative='greater').pvalue,2))\n",
    "\n",
    "# Result shows p-value of t-test for comparing different return methods for NZDUSD 4 hour data.\n",
    "# We can see following p-values from last row(Statistical column) of Table 16. \n",
    "# NZDUSD 4H .11 .01 .71 .29 -.04 -.11 .51 .49 .23 .26 .47 .53\n",
    "\n",
    "# I run above codes multiple times for each case (different data frequencies and different currency pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56ecb82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "24.4\n",
      "3.0\n",
      "0.19\n",
      "-----------------------\n",
      "40.9\n",
      "-31.1\n",
      "0.02\n",
      "-----------------------\n",
      "-20.8\n",
      "49.2\n",
      "0.99\n",
      "-----------------------\n",
      "-4.3\n",
      "3.7\n",
      "0.64\n",
      "-----------------------\n",
      "19.9\n",
      "-29.5\n",
      "0.04\n",
      "-----------------------\n",
      "-16.5\n",
      "51.0\n",
      "0.99\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------- Annualized Sharpe Ratio (Example)\n",
    "from IPython.display import display\n",
    "df1 = pd.read_excel('real_output/Outputs'+i+'/Simple/buy and sell/equity.xlsx')\n",
    "df2 = pd.read_excel('real_output/Outputs'+i+'/Simple/only buy/equity.xlsx')\n",
    "df3 = pd.read_excel('real_output/Outputs'+i+'/Simple/only sell/equity.xlsx')\n",
    "df4 = pd.read_excel('real_output/Outputs'+i+'/Log/buy and sell/equity.xlsx')\n",
    "df5 = pd.read_excel('real_output/Outputs'+i+'/Log/only buy/equity.xlsx')\n",
    "df6 = pd.read_excel('real_output/Outputs'+i+'/Log/only sell/equity.xlsx')\n",
    "z_list=[df1,df2,df3,df4,df5,df6]\n",
    "tr=252*6 # daily data -> tr=252. 4hour data -> tr=252*6 \n",
    "for z in z_list:\n",
    "  print('-----------------------')\n",
    "  RIDGE=z['RIDGE'].pct_change()\n",
    "  RIDGE_S=RIDGE.mean()/RIDGE.std()*((tr)**(1/2))\n",
    "\n",
    "  KNN=z['KNN'].pct_change()\n",
    "  KNN_S=KNN.mean()/KNN.std()*((tr)**(1/2))\n",
    "\n",
    "  RF=z['RF'].pct_change()\n",
    "  RF_S=RF.mean()/RF.std()*((tr)**(1/2))\n",
    "\n",
    "  XGBOOST=z['XGBOOST'].pct_change()\n",
    "  XGBOOST_S=XGBOOST.mean()/XGBOOST.std()*((tr)**(1/2))\n",
    "\n",
    "  GBDT=z['GBDT'].pct_change()\n",
    "  GBDT_S=GBDT.mean()/GBDT.std()*((tr)**(1/2))\n",
    "\n",
    "  ANN=z['ANN'].pct_change()\n",
    "  ANN_S=ANN.mean()/ANN.std()*((tr)**(1/2))\n",
    "\n",
    "  LSTM=z['LSTM'].pct_change()\n",
    "  LSTM_S=LSTM.mean()/LSTM.std()*((tr)**(1/2))\n",
    "\n",
    "  GRU=z['GRU'].pct_change()\n",
    "  GRU_S=GRU.mean()/GRU.std()*((tr)**(1/2))\n",
    "\n",
    "  ML1_S=(GRU_S+ANN_S+LSTM_S)/3\n",
    "  ML2_S=(RIDGE_S+KNN_S+RF_S+XGBOOST_S+GBDT_S)/5\n",
    "\n",
    "  print(round(ML1_S*100,1))\n",
    "  print(round(ML2_S*100,1))\n",
    "  ML1=(GRU+ANN+LSTM)/3\n",
    "  ML2=(RIDGE+KNN+RF+XGBOOST+GBDT)/5\n",
    "  from scipy import stats\n",
    "\n",
    "  print(round(stats.ttest_ind(ML1.dropna(), ML2.dropna(),alternative='greater').pvalue,2))\n",
    "\n",
    "  # Result: Last number of each section will shows p-value of comparising between ML(nn) and ML(o)/.\n",
    "  # We can see last number of each section from last 2 rows of Table 13.\n",
    "\n",
    "  # Result: First 2 numbers of each section will shows ASR of integrated strategies. ML(NN) and ML(O)/\n",
    "  # We can see first 2 numbers of each section from last 2 rows of Table 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70bdb7e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-31T18:35:49.374282Z",
     "iopub.status.busy": "2023-12-31T18:35:49.373591Z",
     "iopub.status.idle": "2023-12-31T18:35:49.378675Z",
     "shell.execute_reply": "2023-12-31T18:35:49.377770Z"
    },
    "id": "Va_ImgVGtl8L",
    "papermill": {
     "duration": 0.052401,
     "end_time": "2023-12-31T18:35:49.380677",
     "exception": false,
     "start_time": "2023-12-31T18:35:49.328276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_res_full['mae_Model'].mean()\n",
    "\n",
    "# for i in range(len(best_list_hyper)):\n",
    "  # print(best_list_hyper[i]['model__neurons'])\n",
    "\n",
    "# ---------------------------------- Plotting\n",
    "# plt.figure(figsize=(30,15))\n",
    "# #df_outputs = df_outputs.set_index('time')\n",
    "# plt.plot(df_outputs.index, df_outputs['equity_BAH']/(10**3),color='red',label='Buy&Hold')\n",
    "# plt.plot(df_outputs.index, df_outputs['RIDGE']/(10**3),color='green',label='RIDGE')\n",
    "# plt.plot(df_outputs.index, df_outputs['SVM']/(10**3),color='blue',label='SVM')\n",
    "# plt.plot(df_outputs.index, df_outputs['KNN']/(10**3),color='yellow',label='KNN')\n",
    "# plt.plot(df_outputs.index, df_outputs['RF']/(10**3),color='orange',label='RF')\n",
    "# plt.plot(df_outputs.index, df_outputs['XGBOOST']/(10**3),color='grey',label='XGBOOST')\n",
    "# plt.plot(df_outputs.index, df_outputs['GBDT']/(10**3),color='black',label='GBDT')\n",
    "# plt.plot(df_outputs.index, df_outputs['MA']/(10**3),color='pink',label='MA')\n",
    "# plt.xlabel('Rate of current to starting capital')\n",
    "# plt.legend()\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3dbb2e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-31T18:35:49.471142Z",
     "iopub.status.busy": "2023-12-31T18:35:49.470384Z",
     "iopub.status.idle": "2023-12-31T18:35:49.474676Z",
     "shell.execute_reply": "2023-12-31T18:35:49.473724Z"
    },
    "id": "M1v9o9utuybN",
    "papermill": {
     "duration": 0.052197,
     "end_time": "2023-12-31T18:35:49.476745",
     "exception": false,
     "start_time": "2023-12-31T18:35:49.424548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_summary_OUTPUTS.to_csv('df_summary_OUTPUTS.csv',index=False) # save to notebook output\n",
    "# df_outputs.to_csv('df_outputs.csv',index=False) # save to notebook output\n",
    "# df_summary_OUTPUTS.to_excel('table-10.xlsx')\n",
    "# df_outputs.to_excel('xaxa.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36b1eff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-31T18:35:49.568254Z",
     "iopub.status.busy": "2023-12-31T18:35:49.567957Z",
     "iopub.status.idle": "2023-12-31T18:35:49.589010Z",
     "shell.execute_reply": "2023-12-31T18:35:49.588070Z"
    },
    "id": "0m1V7p15CFqV",
    "papermill": {
     "duration": 0.069058,
     "end_time": "2023-12-31T18:35:49.591091",
     "exception": false,
     "start_time": "2023-12-31T18:35:49.522033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------- Note\n",
    "######## https://audhiaprilliant.medium.com/walk-forward-optimization-cross-validation-technique-for-time-series-data-61739f58f2c\n",
    "# df = pd.read_csv('data/boston.csv')\n",
    "# model = Ridge()\n",
    "# param_search = {'alpha' : [0.5,0.6,0.7,1]}\n",
    "# df=df.reset_index(drop=True)\n",
    "# #test=test.reset_index(drop=True)\n",
    "# train_indices=df.iloc[:400].index.values\n",
    "# valid_indices=df.iloc[400:].index.values\n",
    "# X_train=df[['zn']]\n",
    "# y_train = df[['crim']]\n",
    "# custom_cv = [[train_indices,valid_indices]]\n",
    "# model_grid = GridSearchCV(estimator=model,cv=custom_cv,\n",
    "#                           param_grid=param_search,scoring='neg_mean_absolute_error') #\n",
    "# model_grid.fit(X_train,y_train)\n",
    "# print('METHOD 1:',model_grid.cv_results_)\n",
    "# # mean test score - -0.4503429\n",
    "# TRAIN=df.iloc[:400]\n",
    "# TEST=df.iloc[400:]\n",
    "# X=TRAIN[['zn']]\n",
    "# Y=TRAIN[['crim']]\n",
    "# XTEST=TEST[['zn']]\n",
    "# YTEST=TEST[['crim']]\n",
    "# model=Ridge(alpha=0.5)\n",
    "# check=model.fit(X,Y)\n",
    "# PRED=check.predict(XTEST)\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# print('METHOD 2: ',mean_absolute_error(YTEST,PRED))\n",
    "# model_grid.cv_results_['mean_test_score'][0]\n",
    "# model_grid.best_params_\n",
    "\n",
    "#df_res_full.to_excel('check.xlsx')\n",
    "# %matplotlib inline\n",
    "# df_res_full.set_index('time')\n",
    "# df_res_full.set_index('time', drop = False, inplace = True)\n",
    "#qs.reports.basic(df_res_full['equity_BAH'])\n",
    "\n",
    "# df=i[['return',\n",
    "#          'ema10','ema20','ema50','ema200', 'ema100',\n",
    "#          'macd_slow', 'macd_fast',\n",
    "#          'rsi',\n",
    "#          'sto_main', 'sto_signal',\n",
    "#          'bb_mid', 'bb_down', 'bb_up',\n",
    "#          'cci','atr','willr', 'ADX_14', 'DMP_14', 'DMN_14',\n",
    "#          'momentum','avg_price','range','ohlc',\n",
    "#          'wd_1','wd_2','wd_3','wd_4','wd_5',\n",
    "#          'mn_1','mn_2','mn_3','mn_4','mn_5','mn_6','mn_7','mn_8','mn_9','mn_10','mn_11','mn_12']]\n",
    "# X_train=df[['ema10','ema20','ema50','ema200', 'ema100',\n",
    "#                        'macd_slow', 'macd_fast',\n",
    "#                        'rsi',\n",
    "#                        'sto_main', 'sto_signal',\n",
    "#                        'bb_mid', 'bb_down', 'bb_up',\n",
    "#                        'cci','atr','willr', 'ADX_14', 'DMP_14', 'DMN_14',\n",
    "#                         'momentum','avg_price','range','ohlc',\n",
    "#                         'wd_1','wd_2','wd_3','wd_4','wd_5',\n",
    "#                         'mn_1','mn_2','mn_3','mn_4','mn_5','mn_6','mn_7','mn_8','mn_9','mn_10','mn_11','mn_12'\n",
    "#                         ]]\n",
    "# y_train=df[['return']]\n",
    "# # param_grid = [{'n_estimators': [10,20]}]\n",
    "# # RF = RandomForestRegressor()\n",
    "# # rfecv = RFECV(estimator=RF, cv=4)\n",
    "# # clf = GridSearchCV(rfecv, param_grid, cv=7)\n",
    "# # clf.fit(X_train, y_train)\n",
    "\n",
    "# rfecv = RFECV(estimator=Ridge(),\n",
    "#               step=1,min_features_to_select=10,n_jobs=2)\n",
    "# clf = Ridge()\n",
    "# CV_rfc = GridSearchCV(clf,\n",
    "#                       param_grid={'alpha':[0.5,1]},\n",
    "#                       cv= 2)\n",
    "# pipeline  = Pipeline([('feature_sele',rfecv),\n",
    "#                       ('clf_cv',CV_rfc)])\n",
    "\n",
    "# pipeline.fit(X_train, y_train)\n",
    "# %matplotlib inline\n",
    "# df_res_full.set_index('time')\n",
    "# df_res_full.set_index('time', drop = False, inplace = True)\n",
    "# qs.stats.information_ratio()\n",
    "\n",
    "#################\n",
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# df1 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/buyandsell/hyper_gru.xlsx')\n",
    "# df2 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/only buy/hyper_gru.xlsx')\n",
    "# df3 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/only sell/hyper_gru.xlsx')\n",
    "# df4 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/buyandsell/hyper_gru.xlsx')\n",
    "# df5 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/onlybuy/hyper_gru.xlsx')\n",
    "# df6 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/onlysell/hyper_gru.xlsx')\n",
    "\n",
    "# df1=df1.col[0]\n",
    "# df2=df2.col[0]\n",
    "# df3=df3.col[0]\n",
    "# df4=df4.col[0]\n",
    "# df5=df5.col[0]\n",
    "# df6=df6.col[0]\n",
    "\n",
    "# for i in [df1,df2,df3,df4,df5,df6]:\n",
    "#   z = list(i.split(\",\"))\n",
    "#   for x in range(5,len(z),8):\n",
    "#     print(z[x])\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# # from google.colab import drive\n",
    "# # drive.mount('/content/gdrive')\n",
    "\n",
    "# df1_6 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/buyandsell/equity-6.xlsx')\n",
    "# df1_6=df1_6[['time','equity_BAH','RIDGE','SVM','KNN','RF','XGBOOST','GBDT']].reset_index(drop=True)\n",
    "# df1_10 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/buyandsell/equity_10.xlsx')\n",
    "# df1_10=df1_10[['time','ema20ema200']].reset_index(drop=True)\n",
    "# df1_ann = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/buyandsell/equity_ann.xlsx')\n",
    "# df1_ann=df1_ann[['ANN']]\n",
    "# df1_lstm = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/buyandsell/equity_lstm.xlsx')\n",
    "# df1_lstm=df1_lstm[['LSTM']]\n",
    "# df1_gru = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/buyandsell/equity_gru.xlsx')\n",
    "# df1_gru=df1_gru[['GRU']]\n",
    "# x1=pd.concat([df1_6, df1_10,df1_ann,df1_lstm,df1_gru], axis=1)\n",
    "\n",
    "# df1_6 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/only buy/equity-6.xlsx')\n",
    "# df1_6=df1_6[['time','equity_BAH','RIDGE','SVM','KNN','RF','XGBOOST','GBDT']].reset_index(drop=True)\n",
    "# df1_10 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/only buy/equity_10.xlsx')\n",
    "# df1_10=df1_10[['time','ema20ema200']].reset_index(drop=True)\n",
    "# df1_ann = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/only buy/equity-ann.xlsx')\n",
    "# df1_ann=df1_ann[['ANN']]\n",
    "# df1_lstm = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/only buy/equity_lstm.xlsx')\n",
    "# df1_lstm=df1_lstm[['LSTM']]\n",
    "# df1_gru = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/only buy/equity_gru.xlsx')\n",
    "# df1_gru=df1_gru[['GRU']]\n",
    "# x2=pd.concat([df1_6, df1_10,df1_ann,df1_lstm,df1_gru], axis=1)\n",
    "\n",
    "# df1_6 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/only sell/equity-6.xlsx')\n",
    "# df1_6=df1_6[['time','equity_BAH','RIDGE','SVM','KNN','RF','XGBOOST','GBDT']].reset_index(drop=True)\n",
    "# df1_10 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/only sell/equity-10.xlsx')\n",
    "# df1_10=df1_10[['time','ema20ema200']].reset_index(drop=True)\n",
    "# df1_ann = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/only sell/equity-ann.xlsx')\n",
    "# df1_ann=df1_ann[['ANN']]\n",
    "# df1_lstm = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/only sell/equity_lstm.xlsx')\n",
    "# df1_lstm=df1_lstm[['LSTM']]\n",
    "# df1_gru = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/simple return/only sell/equity_gru.xlsx')\n",
    "# df1_gru=df1_gru[['GRU']]\n",
    "# x3=pd.concat([df1_6, df1_10,df1_ann,df1_lstm,df1_gru], axis=1)\n",
    "\n",
    "# df1_6 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/buyandsell/equity-6.xlsx')\n",
    "# df1_6=df1_6[['time','equity_BAH','RIDGE','SVM','KNN','RF','XGBOOST','GBDT']].reset_index(drop=True)\n",
    "# df1_10 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/buyandsell/equity-10.xlsx')\n",
    "# df1_10=df1_10[['time','ema20ema200']].reset_index(drop=True)\n",
    "# df1_ann = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/buyandsell/equity-ann.xlsx')\n",
    "# df1_ann=df1_ann[['ANN']]\n",
    "# df1_lstm = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/buyandsell/equity_lstm.xlsx')\n",
    "# df1_lstm=df1_lstm[['LSTM']]\n",
    "# df1_gru = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/buyandsell/equity_gru.xlsx')\n",
    "# df1_gru=df1_gru[['GRU']]\n",
    "# x4=pd.concat([df1_6, df1_10,df1_ann,df1_lstm,df1_gru], axis=1)\n",
    "\n",
    "# df1_6 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/onlybuy/equity-6.xlsx')\n",
    "# df1_6=df1_6[['time','equity_BAH','RIDGE','SVM','KNN','RF','XGBOOST','GBDT']].reset_index(drop=True)\n",
    "# df1_10 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/onlybuy/equity-10.xlsx')\n",
    "# df1_10=df1_10[['ema20ema200']].reset_index(drop=True)\n",
    "# df1_ann = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/onlybuy/equity-ann.xlsx')\n",
    "# df1_ann=df1_ann[['ANN']]\n",
    "# df1_lstm = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/onlybuy/equity_lstm.xlsx')\n",
    "# df1_lstm=df1_lstm[['LSTM']]\n",
    "# df1_gru = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/onlybuy/equity_gru.xlsx')\n",
    "# df1_gru=df1_gru[['GRU']]\n",
    "# x5=pd.concat([df1_6, df1_10,df1_ann,df1_lstm,df1_gru], axis=1)\n",
    "\n",
    "# df1_6 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/onlysell/equity-6.xlsx')\n",
    "# df1_6=df1_6[['time','equity_BAH','RIDGE','SVM','KNN','RF','XGBOOST','GBDT']].reset_index(drop=True)\n",
    "# df1_10 = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/onlysell/equity-10.xlsx')\n",
    "# df1_10=df1_10[['ema20ema200']].reset_index(drop=True)\n",
    "# df1_ann = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/onlysell/equity-ann.xlsx')\n",
    "# df1_ann=df1_ann[['ANN']]\n",
    "# df1_lstm = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/onlysell/equity_lstm.xlsx')\n",
    "# df1_lstm=df1_lstm[['LSTM']]\n",
    "# df1_gru = pd.read_excel('/content/gdrive/MyDrive/1.Own Files/1.MAIN_FILES/Thesis/outputs/eurusd/logreturn/onlysell/equity_gru.xlsx')\n",
    "# df1_gru=df1_gru[['GRU']]\n",
    "# x6=pd.concat([df1_6, df1_10,df1_ann,df1_lstm,df1_gru], axis=1)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# x1=x6\n",
    "# plt.figure(figsize=(15,7))\n",
    "# # plt.figure(figsize=(30,15))\n",
    "# plt.plot(x1['time'],x1['equity_BAH']/(10**3),color='red',label='Buy&Hold',linewidth=0.4)\n",
    "# plt.plot(x1['time'],x1['RIDGE']/(10**3),color='green',label='RIDGE',linewidth=0.4)\n",
    "# plt.plot(x1['time'],x1['SVM']/(10**3),color='blue',label='SVM',linewidth=0.4)\n",
    "# plt.plot(x1['time'],x1['KNN']/(10**3),color='yellow',label='KNN',linewidth=0.4)\n",
    "# plt.plot(x1['time'],x1['RF']/(10**3),color='orange',label='RF',linewidth=0.4)\n",
    "# plt.plot(x1['time'],x1['XGBOOST']/(10**3),color='grey',label='XGBOOST',linewidth=0.4)\n",
    "# plt.plot(x1['time'],x1['GBDT']/(10**3),color='black',label='GBDT',linewidth=0.4)\n",
    "# plt.plot(x1['time'],x1['ema20ema200']/(10**3),color='pink',label='MA',linewidth=0.4)\n",
    "# plt.plot(x1['time'],x1['ANN']/(10**3),color='aqua',label='ANN',linewidth=0.4)\n",
    "# plt.plot(x1['time'],x1['LSTM']/(10**3),color='skyblue',label='LSTM',linewidth=0.4)\n",
    "# plt.plot(x1['time'],x1['GRU']/(10**3),color='yellowgreen',label='GRU',linewidth=0.4)\n",
    "# plt.xlabel('Rate of current to starting capital')\n",
    "# plt.axis('on')\n",
    "# plt.grid(False)\n",
    "# plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\",ncol=6)\n",
    "# plt.tick_params(labelsize=14)\n",
    "# plt.show\n",
    "\n",
    "# # ---------------------------------- Moving Averages\n",
    "# i=df1_d\n",
    "\n",
    "# OUTPUTS=[]\n",
    "# HYPERS=[]\n",
    "# df_summary_OUTPUTS=[]\n",
    "# for short, long in zip(['ema10','ema10','ema10','ema10',\n",
    "#                         'ema20','ema20','ema20',\n",
    "#                         'ema50','ema50',\n",
    "#                         'ema100'],\n",
    "#                          ['ema20','ema50','ema100','ema200',\n",
    "#                           'ema50','ema100','ema200',\n",
    "#                           'ema100','ema200',\n",
    "#                           'ema200']):\n",
    "#   name_in=str(short+long)\n",
    "#   i=i[i.time>='2003-01-01']\n",
    "#   i=i[i.time<='2023-06-30']\n",
    "#   MA_cross = i[['time','open','close',short,long]]\n",
    "#   MA_cross['signal_Model']=0\n",
    "#   MA_cross['signal_Model'][MA_cross[long]<MA_cross[short]]=1\n",
    "#   MA_cross['signal_Model'][MA_cross[long]>MA_cross[short]]=-1\n",
    "#   pipvalue=0.1 # based on lot size\n",
    "#   MA_cross['close_next']=MA_cross['close'].shift(-1)\n",
    "#   MA_cross['open_next']=MA_cross['open'].shift(-1)\n",
    "#   MA_cross['changes']=(MA_cross['close_next']-MA_cross['open_next'])*(10**2)*pipvalue\n",
    "#   MA_cross['equity_BAH'] = MA_cross['changes'].cumsum()+1000\n",
    "\n",
    "#   MA_cross['profit']=0\n",
    "#   MA_cross['cost']=0\n",
    "#   # MA_cross['cost'][MA_cross['signal_Model']!=0]=cost*pipvalue\n",
    "#   MA_cross['cost'][MA_cross['signal_Model']!=0]=MA_cross['close']*1000*0.0002\n",
    "#   MA_cross['cost'][MA_cross['signal_Model']==MA_cross['signal_Model'].shift(1)]=0\n",
    "#   MA_cross['changes_Model']=MA_cross['changes']-MA_cross['cost']\n",
    "\n",
    "#   MA_cross['profit'][(MA_cross['signal_Model'] == 1) &\n",
    "#                       (MA_cross['changes_Model'] > 0)] = abs(MA_cross['changes_Model'])\n",
    "#   MA_cross['profit'][(MA_cross['signal_Model'] == 1) &\n",
    "#                       (MA_cross['changes_Model'] < 0)] = abs(MA_cross['changes_Model'])*-1\n",
    "#   MA_cross['profit'][(MA_cross['signal_Model'] == -1) &\n",
    "#                       (MA_cross['changes_Model'] < 0)] = abs(MA_cross['changes_Model'])\n",
    "#   MA_cross['profit'][(MA_cross['signal_Model'] == -1) &\n",
    "#                       (MA_cross['changes_Model'] > 0)] = abs(MA_cross['changes_Model'])*-1\n",
    "#   MA_cross['profit'][MA_cross['signal_Model']==0]=0\n",
    "#   MA_cross['equity_Model'] = MA_cross['profit'].cumsum()+1000\n",
    "#   ####\n",
    "#   df_summary=pd.DataFrame([MA_cross['time'].iloc[0],\n",
    "#                           MA_cross['time'].iloc[-1],\n",
    "#                       1000, # Start\n",
    "#                       MA_cross['equity_Model'].iloc[-1],  # End\n",
    "#                       MA_cross['profit'][MA_cross['profit']>0].sum(), # Gross profit\n",
    "#                       MA_cross['profit'][MA_cross['profit']<0].sum(), # Gross loss\n",
    "#                       MA_cross['profit'][MA_cross['profit']>0].sum()+MA_cross['profit'][MA_cross['profit']<0].sum(), # Net profit\n",
    "#                       '{:.1%}'.format((MA_cross['profit'][MA_cross['profit']>0].sum()+MA_cross['profit'][MA_cross['profit']<0].sum())/1000), # Return on initial capital\n",
    "#                       MA_cross['profit'][MA_cross['profit']>0].sum()/MA_cross['profit'][MA_cross['profit']<0].sum(), # Profit factor\n",
    "#                       MA_cross['cost'][MA_cross['cost']!=0].count(), # Total number of trades\n",
    "#                       '{:.1%}'.format((MA_cross['cost'][(MA_cross['cost']!=0) & (MA_cross['signal_Model']==-1)].count())/(MA_cross['cost'][MA_cross['cost']!=0].count())), # % sell\n",
    "#                       '{:.1%}'.format((MA_cross['cost'][(MA_cross['cost']!=0) & (MA_cross['signal_Model']==1)].count())/(MA_cross['cost'][MA_cross['cost']!=0].count())), # % buy\n",
    "#                       MA_cross['cost'][(MA_cross['cost']!=0) & (MA_cross['profit']>0)].count(), # winning trades\n",
    "#                       MA_cross['cost'][(MA_cross['cost']!=0) & (MA_cross['profit']<0)].count(), # Lossing trades\n",
    "#                       '{:.1%}'.format((MA_cross['cost'][(MA_cross['cost']!=0) & (MA_cross['profit']>0)].count())/MA_cross['cost'][MA_cross['cost']!=0].count()), #%profitable\n",
    "#                       (MA_cross['profit'][MA_cross['profit']>0].sum()+MA_cross['profit'][MA_cross['profit']<0].sum())/(MA_cross['cost'][MA_cross['cost']!=0].count()), # Total number of trades\n",
    "#                       (MA_cross['profit'][MA_cross['profit']>0].sum())/(MA_cross['cost'][(MA_cross['cost']!=0) & (MA_cross['profit']>0)].count()), # Avg.winning trade\n",
    "#                       (MA_cross['profit'][MA_cross['profit']<0].sum())/(MA_cross['cost'][(MA_cross['cost']!=0) & (MA_cross['profit']<0)].count()), # Avg.lossing trade\n",
    "#                       ((MA_cross['profit'][MA_cross['profit']>0].sum())/(MA_cross['cost'][(MA_cross['cost']!=0) & (MA_cross['profit']>0)].count()))/((MA_cross['profit'][MA_cross['profit']<0].sum())/(MA_cross['cost'][(MA_cross['cost']!=0) & (MA_cross['profit']<0)].count())), # Ratio\n",
    "#                       MA_cross['profit'].max(), # Largest winning trade\n",
    "#                       MA_cross['profit'].min(), # Largest lossing trade\n",
    "#                       MA_cross['cost'].sum(),\n",
    "#                       calculate_max_drawdown((MA_cross['equity_Model']-MA_cross['equity_Model'].shift(1))/MA_cross['equity_Model'].shift(1)),\n",
    "#                       calculate_sharpe_ratio((MA_cross['equity_Model']-MA_cross['equity_Model'].shift(1))/MA_cross['equity_Model'].shift(1),0),\n",
    "#                       calculate_roi(MA_cross['equity_Model'])\n",
    "#                       ],\n",
    "#                       columns=[str(name_in)],\n",
    "#                       index=['start_date','end_date','Start','End','Gross profit','Gross loss','Total Net profit', 'Return on initial capital',\n",
    "#                             'Profit factor','Total number of trades',\n",
    "#                             '%sell','%buy','Winning trades','Lossing trades','%profitable','Avg.Trade Net profit',\n",
    "#                             'Avg.Winning trade','Avg.Lossing trade','Ratio Avg.Win:Avg.Loss','Largest Winning trade','Largest Lossing trade','Cost',\n",
    "#                             'MD', 'IR/SR','ROI'])\n",
    "#   df_summary_OUTPUTS.append(df_summary)\n",
    "#   df_res_full=MA_cross.rename(columns = {'equity_Model':str(name_in)})\n",
    "#   OUTPUTS.append(df_res_full[['time','equity_BAH',str(name_in)]])\n",
    "# df_outputs=pd.concat([OUTPUTS[0]['time'].reset_index(),\n",
    "#                       OUTPUTS[0]['ema10ema20'].reset_index(),\n",
    "#                       OUTPUTS[1]['ema10ema50'].reset_index(),\n",
    "#                       OUTPUTS[2]['ema10ema100'].reset_index(),\n",
    "#                       OUTPUTS[3]['ema10ema200'].reset_index(),\n",
    "#                       OUTPUTS[4]['ema20ema50'].reset_index(),\n",
    "#                       OUTPUTS[5]['ema20ema100'].reset_index(),\n",
    "#                       OUTPUTS[6]['ema20ema200'].reset_index(),\n",
    "#                       OUTPUTS[7]['ema50ema100'].reset_index(),\n",
    "#                       OUTPUTS[8]['ema50ema200'].reset_index(),\n",
    "#                       OUTPUTS[9]['ema100ema200'].reset_index()],axis=1) #'RIDGE','SVM','KNN'\n",
    "# df_outputs = df_outputs.T.drop_duplicates().T\n",
    "# df_summary_OUTPUTS = pd.concat(df_summary_OUTPUTS,axis=1)\n",
    "\n",
    "# history = model_grid.best_estimator_.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, verbose=0)\n",
    "# plt.plot(history.history_['loss'], label='Train MAE')\n",
    "# plt.plot(history.history_['val_loss'], label='Test MAE')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Mean Absolute Error')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # fig, (ax) = plt.subplots(1, 1,figsize=(24, 8))\n",
    "# # for i in ['equity_BAH','GRU']:\n",
    "# #   ax.plot(df_outputs.time, df_outputs[i],linewidth=0.5, label=i)\n",
    "# #   ax.legend(labelcolor='linecolor')\n",
    "\n",
    "# df_summary_OUTPUTS.to_csv('df_summary_OUTPUTS.csv',index=False) # save to notebook output\n",
    "# HYPERS.to_csv('HYPERS.csv',index=False) # save to notebook output\n",
    "# HYPERS = pd.DataFrame({'col':HYPERS})\n",
    "# df_outputs.to_csv('df_outputs.csv',index=False) # save to notebook output\n",
    "# HYPERS.to_csv('eurusd-d-hyper-6.csv')\n",
    "# len(df_outputs)\n",
    "# df_summary_OUTPUTS.to_excel('table-ann.xlsx')\n",
    "# df_outputs.to_excel('equity-ann.xlsx')\n",
    "# HYPERS = pd.DataFrame({'col':HYPERS})\n",
    "# HYPERS.to_excel('hyper-ann.xlsx')\n",
    "\n",
    "# HYPERS - hyper\n",
    "# df_outputs - equity\n",
    "# df_summary_OUTPUTS - table\n",
    "# df_summary_OUTPUTS"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4203806,
     "sourceId": 7254799,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29403.666568,
   "end_time": "2023-12-31T18:35:54.513177",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-31T10:25:50.846609",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
